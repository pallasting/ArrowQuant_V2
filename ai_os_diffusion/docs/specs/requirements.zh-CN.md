# 需求文档：统一扩散架构

## 概述

统一扩散架构（Unified Diffusion Architecture）用热力学扩散模型替代自回归（AR）模型，通过单一的共享 Score Network 实现统一的多模态生成（文本、代码、图像、音频）。该系统与现有的 ArrowEngine 基础设施集成，支持使用 ArrowStorage 进行记忆引导生成，并实现了具有边缘部署能力的 5 级渐进式自我进化机制。

## 术语表

- **Score_Network（评分网络）**：统一的神经网络，学习所有模态去噪过程中对数概率分布的梯度（评分函数）
- **DiffusionCore（扩散核心）**：核心推理引擎，管理基于扩散生成的迭代去噪过程
- **ArrowEngine**：现有的推理路由层，管理模型加载和执行
- **ArrowStorage**：使用 Hopfield 网络进行基于向量的记忆检索的存储系统
- **ArrowQuant**：支持 INT2/INT4 权重压缩和零拷贝加载的量化系统
- **MemoryConditioner（记忆调节器）**：将 ArrowStorage 检索结果转换为扩散条件向量的组件
- **NoiseScheduler（噪声调度器）**：管理离散和连续模态扩散时间步噪声水平的组件
- **DiscreteSampler（离散采样器）**：使用基于掩码去噪的离散模态（文本、代码）采样器
- **ContinuousSampler（连续采样器）**：使用高斯噪声去噪的连续模态（图像、音频）采样器
- **ControlNet**：轻量级辅助网络，在不修改基础权重的情况下注入结构或行为约束
- **LoRA**：低秩适应，用于以最少的参数更新进行高效模型微调
- **EBM（能量模型）**：用于约束验证和引导的基于能量的模型
- **Consistency_Distillation（一致性蒸馏）**：将多步扩散压缩为 1-4 步同时保持质量的训练技术
- **MDLM**：用于离散文本生成的掩码扩散语言模型
- **SEDD**：用于离散 token 生成的评分熵离散扩散
- **DiT**：用于图像生成的扩散 Transformer 架构
- **VAE**：用于将图像编码/解码到/从潜在空间的变分自编码器
- **Modality（模态）**：正在生成的数据类型（文本、代码、图像、音频）
- **Projection_Head（投影头）**：模态特定的轻量级解码器，将共享表示投影到模态空间

## 需求

### 需求 1：离散扩散文本和代码生成

**用户故事：** 作为开发者，我希望使用离散扩散模型生成文本和代码，以便利用双向上下文并支持超越从左到右生成的填充能力。

#### 验收标准

1. 当收到文本生成请求时，DiffusionCore 应初始化一个完全掩码的 token 序列
2. 当 NoiseScheduler 对文本执行前向加噪时，系统应根据噪声调度应用 token 掩码
3. 当 DiscreteSampler 执行去噪步骤时，系统应根据模型置信度分数取消 token 掩码
4. 当使用填充上下文生成文本时，系统应保留提供的前缀和后缀 token，同时生成中间内容
5. 当文本生成完成时，系统应返回一个连贯的文本序列，其困惑度在等效 AR 基线的 20% 以内
6. 当请求代码生成时，系统应使用与文本生成相同的离散扩散过程
7. 当应用 4 步一致性蒸馏时，系统应在 CPU 上使用 INT2 量化的 350M 参数模型在 500ms 内完成文本生成

### 需求 2：连续扩散图像生成

**用户故事：** 作为用户，我希望使用扩散模型从文本描述生成图像，以便根据我的记忆和偏好创建视觉内容。

#### 验收标准

1. 当收到图像生成请求时，DiffusionCore 应在 VAE 潜在空间中初始化高斯噪声
2. 当 VAE 编码器处理图像时，系统应产生具有降维的潜在表示
3. 当 ContinuousSampler 执行去噪步骤时，系统应对潜在表示应用基于评分的更新
4. 当图像生成完成时，VAE 解码器应从去噪的潜在表示重建像素空间图像
5. 当使用 600M 参数以下的模型生成 512x512 图像时，系统应在 CPU 上 30 秒内完成生成
6. 当对图像模型应用 INT4 量化时，系统应保持模型大小在 200MB 以下
7. 当请求记忆引导的图像生成时，系统应将 ArrowStorage 检索结果作为条件纳入

### 需求 3：连续扩散音频生成

**用户故事：** 作为用户，我希望使用扩散模型从文本生成语音和音频，以便为虚拟化身创建自然 sounding 的语音输出。

#### 验收标准

1. 当收到文本转语音请求时，DiffusionCore 应在音频波形或潜在空间中初始化噪声
2. 当音频投影头解码音频时，系统应产生最低 16kHz 采样率的波形
3. 当请求 TTS 生成时，系统应在 2 秒内完成端到端生成
4. 当使用 5 秒参考音频请求零样本语音克隆时，系统应生成匹配参考语音特征的语音
5. 当音频生成完成时，系统应输出具有自然韵律和可理解性的音频

### 需求 4：统一评分网络架构

**用户故事：** 作为系统架构师，我希望所有模态共享单个 Transformer 骨干，以便最小化内存占用并实现跨模态知识迁移。

#### 验收标准

1. Score_Network 应包含处理所有模态的 SharedTransformer 组件
2. 当计算模型参数时，SharedTransformer 应至少占总参数的 90%
3. 当处理任何模态的输入时，Score_Network 应应用模态特定嵌入以区分模态类型
4. 当在时间步 t 处理输入时，Score_Network 应应用正弦时间嵌入来编码去噪步骤
5. 当添加新模态时，系统应只需要训练参数少于 10M 的新 Projection_Head
6. 当同时生成多个模态时，SharedTransformer 应执行单次前向传播，为所有 Projection_Head 产生隐藏状态
7. Score_Network 应支持文本、代码、图像和音频模态的独立 Projection_Head

### 需求 5：记忆引导扩散条件

**用户故事：** 作为用户，我希望我的个人记忆能引导内容生成，以便生成的输出反映我的经历和偏好。

#### 验收标准

1. 当生成请求包含记忆引导时，MemoryConditioner 应使用用户提示查询 ArrowStorage
2. 当 ArrowStorage 返回检索结果时，MemoryConditioner 应从 top-K 记忆中提取嵌入向量
3. 当提取记忆嵌入时，MemoryConditioner 应将其投影到条件维度
4. 当 Score_Network 执行去噪时，系统应通过交叉注意力机制注入条件向量
5. 当记忆引导生成完成时，系统应产生与检索记忆语义相关的输出，相关性率超过 80%
6. 当应用记忆条件时，系统应在 10ms 内完成条件投影

### 需求 6：不确定性感知自我进化触发

**用户故事：** 作为系统设计者，我希望模型能检测其何时不确定，以便仅在需要时触发自我进化机制。

#### 验收标准

1. 当 Score_Network 执行去噪步骤时，不确定性估计器应计算去噪残差范数
2. 当计算不确定性时，不确定性估计器应按时间步 t 的预期噪声水平归一化残差
3. 当不确定性指标超过阈值 1.5 时，系统应触发自我进化机制
4. 当不确定性低于阈值时，系统应继续正常生成而不进行进化
5. 当针对人工标注的不确定场景评估时，不确定性估计器应达到 0.7 以上的相关性
6. 当测量误触发率时，系统应保持错误的进化触发率在 5% 以下

### 需求 7：一致性蒸馏加速

**用户故事：** 作为部署到边缘设备的开发者，我希望在质量损失最小的情况下实现快速生成，以便系统可以在资源受限的硬件上实时运行。

#### 验收标准

1. 当应用一致性蒸馏训练时，系统应将 50 步扩散过程压缩为 1-4 步
2. 当使用 4 步蒸馏模型生成时，系统应保持 50 步模型至少 90% 的质量
3. 当在 CPU 上使用 INT2 量化的 350M 参数测量文本生成延迟时，系统应在 500ms 内完成生成
4. 当应用一致性蒸馏时，系统应保留使用可变步数进行质量-速度权衡的能力

### 需求 8：ControlNet 结构约束

**用户故事：** 作为开发者，我希望在生成中注入行为和结构约束，以便输出遵循特定模式而无需重新训练基础模型。

#### 验收标准

1. 当加载 ControlNet 时，系统应支持到 Score_Network 的零初始化残差连接
2. 当多个 ControlNet 处于活动状态时，EvolutionRouter 应通过加权和组合其输出
3. 当应用 ControlNet 时，系统应保持 ControlNet 参数数量在基础模型参数的 10% 以下
4. 当 CoT-ControlNet 处于活动状态时，系统应在文本生成中强制执行思维链推理结构
5. 当 ToolSchema-ControlNet 处于活动状态时，系统应强制工具调用输出的 JSON 模式合规性
6. 当存储 ControlNet 权重时，系统应使用支持 ArrowQuant 的 Parquet V2 格式

### 需求 9：渐进式 5 级自我进化

**用户故事：** 作为系统架构师，我希望有一个从零训练到完全微调的渐进进化机制，以便系统可以根据不确定性水平高效适应。

#### 验收标准

1. EvolutionRouter 应通过多个评分预测的加权和实现 Level 0 评分组合
2. EvolutionRouter 应通过约 10% 参数训练实现 Level 1 ControlNet 注入以获取结构偏好
3. EvolutionRouter 应通过约 1% 参数训练实现 Level 2 LoRA 微调以获取领域知识
4. EvolutionRouter 应通过不确定性驱动的层解冻实现 Level 3 选择性骨干微调
5. EvolutionRouter 应实现 Level 4 完整模型微调以进行长期巩固
6. 当检测到不确定性时，EvolutionRouter 应根据不确定性大小选择适当的进化级别
7. 当在任何级别完成进化时，系统应在持久化适应之前验证改进

### 需求 10：基于能量模型的约束融合

**用户故事：** 作为开发者，我希望对生成强制执行硬约束，以便输出满足物理或逻辑要求。

#### 验收标准

1. 当注册 EBM 时，EvolutionRouter 应计算能量梯度以进行约束执行
2. 当将评分与 EBM 约束组合时，系统应应用公式：final_score = diffusion_score - eta * energy_gradient
3. 当 EBM 约束处于活动状态时，系统应支持具有独立权重的多个同时能量模型
4. 当 EBM 验证失败时，系统应拒绝生成的样本并使用更强的约束权重重试

### 需求 11：统一噪声调度

**用户故事：** 作为开发者，我希望有一个同时处理离散和连续模态的噪声调度器，以便系统在生成类型间具有一致的行为。

#### 验收标准

1. NoiseScheduler 应支持离散掩码调度和连续高斯噪声调度
2. 当在离散模式下运行时，NoiseScheduler 应计算作为时间步函数的掩码概率
3. 当在连续模式下运行时，NoiseScheduler 应计算作为时间步函数的噪声标准差
4. NoiseScheduler 应支持余弦、线性和自定义调度函数
5. 当生成推理时间步时，NoiseScheduler 应支持均匀和非均匀采样策略
6. 当在训练期间添加噪声时，NoiseScheduler 应根据模态应用适当的噪声类型

### 需求 12：ArrowEngine 集成

**用户故事：** 作为用户，我希望通过现有 ArrowEngine API 无缝访问扩散生成，以便无需更改工作流程即可使用 AR 和扩散模型。

#### 验收标准

1. ArrowEngine 应保持与现有 encode() 和 generate() 方法的向后兼容性
2. 当指定 mode="diffusion" 时，ArrowEngine 应将请求路由到 DiffusionCore 而非 InferenceCore
3. ArrowEngine 应暴露新的 diffuse() 方法，接受 prompt、modality、num_steps 和 guidance_scale 参数
4. 当以 memory_guided=True 调用 diffuse() 时，系统应自动查询 ArrowStorage 获取条件
5. 当以 modality="text" 调用 diffuse() 时，系统应返回解码的文本字符串
6. 当以 modality="image" 调用 diffuse() 时，系统应返回像素空间 numpy 数组或张量
7. 当以 modality="audio" 调用 diffuse() 时，系统应返回波形 numpy 数组

### 需求 13：Parquet V2 存储格式

**用户故事：** 作为系统架构师，我希望所有扩散模型权重以 Parquet V2 格式存储，以便利用零拷贝加载和 ArrowQuant 压缩。

#### 验收标准

1. 当存储 Score_Network 权重时，系统应使用 Parquet V2 文件格式
2. 当存储 Projection_Head 权重时，系统应使用 Parquet V2 文件格式
3. 当存储 ControlNet 权重时，系统应使用 Parquet V2 文件格式
4. 当存储 VAE 权重时，系统应使用 Parquet V2 文件格式
5. 系统应支持所有存储权重的 ArrowQuant INT2 和 INT4 量化
6. 当加载权重时，系统应支持零拷贝内存映射
7. 当加载权重时，系统应支持访问时的惰性去量化

### 需求 14：分层部署支持

**用户故事：** 作为部署工程师，我希望将适当的模型大小部署到不同的硬件层级，以便系统从移动设备到云服务器都能高效运行。

#### 验收标准

1. 当部署到具有 2-4GB RAM 的边缘设备时，系统应支持 INT2 量化下参数少于 100M、总大小在 35MB 以下的模型
2. 当部署到具有 8+GB RAM 的本地工作站时，系统应支持 INT4 量化下参数少于 600M、总大小在 200MB 以下的模型
3. 当部署到云 GPU 服务器时，系统应支持高达 3B 参数的模型
4. 当部署到边缘设备时，系统应至少支持文本和音频模态
5. 当部署到本地工作站时，系统应支持文本、音频和图像模态
6. 当部署到云服务器时，系统应支持包括统一 Score_Network 在内的所有模态

### 需求 15：模型元数据和配置

**用户故事：** 作为开发者，我希望扩散模型具有全面的元数据，以便系统可以根据模型能力自动配置自身。

#### 验收标准

1. 当存储扩散模型时，系统应包含 model_type="unified_diffusion" 的 metadata.json 文件
2. metadata.json 应指定 diffusion_config，包括 hidden_dim、num_layers、num_heads 和 intermediate_dim
3. metadata.json 应指定调度器配置，包括 type、num_train_steps 和 num_inference_steps
4. metadata.json 应将 supported_modalities 列为数组
5. metadata.json 应指示 consistency_distilled 是 true 还是 false
6. metadata.json 应指定量化方法和 bit_width
7. 当加载模型时，系统应解析 metadata.json 以正确配置 DiffusionCore

### 需求 16：多模态并行生成

**用户故事：** 作为与虚拟化身交互的用户，我希望同步输出文本、音频和视觉，以便化身自然响应而无级联延迟。

#### 验收标准

1. 当请求多模态生成时，Score_Network 应对所有模态执行单次前向传播
2. 当 SharedTransformer 产生隐藏状态时，系统应同时将其路由到所有活动的 Projection_Head
3. 当同时生成文本、音频和化身参数时，系统应确保时间同步
4. 当多模态生成完成时，系统应返回具有对齐时间信息的所有输出

### 需求 17：与 AR 模型的向后兼容性

**用户故事：** 作为系统操作员，我希望保持现有 AR 模型功能，以便可以逐步过渡到扩散模型而不破坏现有工作流程。

#### 验收标准

1. 当指定 mode="ar" 时，ArrowEngine 应路由到现有 InferenceCore
2. 系统应支持同时加载 AR 模型和扩散模型
3. 当 AR 模型处于活动状态时，系统应继续支持现有 LoRA Router 功能
4. 系统不应允许混合 AR 模型 LoRA 与扩散模型 LoRA
5. 当在 AR 和扩散模式之间切换时，系统应对公共参数保持一致的 API 行为

### 需求 18：自我进化闭环

**用户故事：** 作为系统架构师，我希望有一个从记忆到生成再到进化的完整反馈循环，以便系统基于使用持续改进。

#### 验收标准

1. 当生成在高不确定性下完成时，系统应触发适当的进化级别
2. 当进化产生适应时，系统应在持久化之前验证改进
3. 当适应被验证后，系统应将其存储到 ArrowStorage 以供未来检索
4. 当遇到类似上下文时，系统应检索并应用学习到的适应
5. 系统应维护闭环：ArrowStorage → MemoryConditioner → Score_Network → UncertaintyEstimator → EvolutionRouter → ArrowStorage
