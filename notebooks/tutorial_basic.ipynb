{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM 压缩系统 - 基础教程\n",
    "\n",
    "本教程介绍 LLM 集成压缩系统的基本使用方法，包括：\n",
    "- 系统初始化\n",
    "- 基本压缩和重构\n",
    "- 质量评估\n",
    "- 实体提取\n",
    "\n",
    "## 前置要求\n",
    "\n",
    "- Python 3.10+\n",
    "- 已安装 llm-compression 包\n",
    "- LLM API 在端口 8045 运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 添加项目路径\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from llm_compression import (\n",
    "    Config,\n",
    "    LLMClient,\n",
    "    ModelSelector,\n",
    "    LLMCompressor,\n",
    "    LLMReconstructor,\n",
    "    QualityEvaluator,\n",
    "    MemoryType,\n",
    "    QualityLevel\n",
    ")\n",
    "\n",
    "print(\"✅ 依赖导入成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载配置文件\n",
    "config = Config.from_yaml(\"../config.yaml\")\n",
    "\n",
    "print(f\"LLM Endpoint: {config.llm.cloud_endpoint}\")\n",
    "print(f\"Storage Path: {config.storage.storage_path}\")\n",
    "print(f\"Min Compress Length: {config.compression.min_compress_length}\")\n",
    "print(\"✅ 配置加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 初始化组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 LLM 客户端\n",
    "llm_client = LLMClient(\n",
    "    endpoint=config.llm.cloud_endpoint,\n",
    "    timeout=config.llm.timeout,\n",
    "    max_retries=config.llm.max_retries\n",
    ")\n",
    "\n",
    "# 初始化模型选择器\n",
    "model_selector = ModelSelector(\n",
    "    cloud_endpoint=config.llm.cloud_endpoint\n",
    ")\n",
    "\n",
    "# 初始化压缩器\n",
    "compressor = LLMCompressor(\n",
    "    llm_client=llm_client,\n",
    "    model_selector=model_selector,\n",
    "    min_compress_length=config.compression.min_compress_length\n",
    ")\n",
    "\n",
    "# 初始化重构器\n",
    "reconstructor = LLMReconstructor(\n",
    "    llm_client=llm_client,\n",
    "    quality_threshold=config.compression.quality_threshold\n",
    ")\n",
    "\n",
    "# 初始化质量评估器\n",
    "evaluator = QualityEvaluator()\n",
    "\n",
    "print(\"✅ 所有组件初始化成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 准备测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例记忆文本\n",
    "original_text = \"\"\"\n",
    "On January 15, 2024, John Smith met with Mary Johnson at the downtown office \n",
    "located at 123 Main Street. The meeting started at 3:00 PM and lasted approximately \n",
    "2 hours. They discussed the Q4 budget proposal, which totals $1.2 million for the \n",
    "upcoming fiscal year.\n",
    "\n",
    "The meeting covered three main topics:\n",
    "1. Marketing budget allocation - $400,000 for digital campaigns\n",
    "2. Engineering team expansion - hiring 5 new developers at $120,000 each\n",
    "3. Product roadmap for 2024 - launching 3 new features in Q1 and Q2\n",
    "\n",
    "Mary agreed to send the revised proposal by Friday, January 19, 2024, and \n",
    "scheduled a follow-up meeting for January 25, 2024 at 2:00 PM to finalize \n",
    "the budget details. John will review the proposal and provide feedback by \n",
    "January 22, 2024.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(f\"原始文本长度: {len(original_text)} 字符\")\n",
    "print(f\"原始文本大小: {len(original_text.encode('utf-8'))} 字节\")\n",
    "print(f\"\\n原始文本预览:\\n{original_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 压缩记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩记忆\n",
    "compressed = await compressor.compress(\n",
    "    text=original_text,\n",
    "    memory_type=MemoryType.TEXT\n",
    ")\n",
    "\n",
    "# 显示压缩结果\n",
    "print(\"=== 压缩结果 ===\")\n",
    "print(f\"Memory ID: {compressed.memory_id}\")\n",
    "print(f\"Summary Hash: {compressed.summary_hash}\")\n",
    "print(f\"\\n压缩元数据:\")\n",
    "print(f\"  原始大小: {compressed.compression_metadata.original_size} 字节\")\n",
    "print(f\"  压缩后大小: {compressed.compression_metadata.compressed_size} 字节\")\n",
    "print(f\"  压缩比: {compressed.compression_metadata.compression_ratio:.2f}x\")\n",
    "print(f\"  使用模型: {compressed.compression_metadata.model_used}\")\n",
    "print(f\"  压缩耗时: {compressed.compression_metadata.compression_time_ms:.2f}ms\")\n",
    "\n",
    "print(f\"\\n提取的实体:\")\n",
    "for entity_type, values in compressed.entities.items():\n",
    "    if values:\n",
    "        print(f\"  {entity_type}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 重构记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重构记忆\n",
    "reconstructed = await reconstructor.reconstruct(\n",
    "    compressed=compressed,\n",
    "    verify_quality=True\n",
    ")\n",
    "\n",
    "# 显示重构结果\n",
    "print(\"=== 重构结果 ===\")\n",
    "print(f\"重构耗时: {reconstructed.reconstruction_time_ms:.2f}ms\")\n",
    "print(f\"置信度: {reconstructed.confidence:.2f}\")\n",
    "\n",
    "if reconstructed.warnings:\n",
    "    print(f\"\\n警告:\")\n",
    "    for warning in reconstructed.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "print(f\"\\n重构文本:\\n{reconstructed.full_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 质量评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估压缩质量\n",
    "metrics = evaluator.evaluate(\n",
    "    original=original_text,\n",
    "    reconstructed=reconstructed.full_text,\n",
    "    compressed=compressed\n",
    ")\n",
    "\n",
    "# 显示质量指标\n",
    "print(\"=== 质量指标 ===\")\n",
    "print(f\"压缩比: {metrics.compression_ratio:.2f}x\")\n",
    "print(f\"语义相似度: {metrics.semantic_similarity:.2f}\")\n",
    "print(f\"实体准确率: {metrics.entity_accuracy:.2f}\")\n",
    "print(f\"BLEU 分数: {metrics.bleu_score:.2f}\")\n",
    "print(f\"重构延迟: {metrics.reconstruction_latency_ms:.2f}ms\")\n",
    "print(f\"综合分数: {metrics.overall_score:.2f}\")\n",
    "\n",
    "if metrics.warnings:\n",
    "    print(f\"\\n警告:\")\n",
    "    for warning in metrics.warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "# 可视化结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 压缩比对比\n",
    "ax1.bar(['原始', '压缩后'], \n",
    "        [compressed.compression_metadata.original_size, \n",
    "         compressed.compression_metadata.compressed_size])\n",
    "ax1.set_ylabel('大小 (字节)')\n",
    "ax1.set_title(f'压缩效果 ({metrics.compression_ratio:.2f}x)')\n",
    "\n",
    "# 质量指标\n",
    "quality_metrics = {\n",
    "    '语义相似度': metrics.semantic_similarity,\n",
    "    '实体准确率': metrics.entity_accuracy,\n",
    "    'BLEU 分数': metrics.bleu_score,\n",
    "    '综合分数': metrics.overall_score\n",
    "}\n",
    "ax2.barh(list(quality_metrics.keys()), list(quality_metrics.values()))\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_xlabel('分数')\n",
    "ax2.set_title('质量指标')\n",
    "ax2.axvline(x=0.85, color='r', linestyle='--', label='阈值 (0.85)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 文本对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比原文和重构文本\n",
    "from difflib import unified_diff\n",
    "\n",
    "original_lines = original_text.split('\\n')\n",
    "reconstructed_lines = reconstructed.full_text.split('\\n')\n",
    "\n",
    "diff = list(unified_diff(\n",
    "    original_lines,\n",
    "    reconstructed_lines,\n",
    "    lineterm='',\n",
    "    fromfile='原文',\n",
    "    tofile='重构'\n",
    "))\n",
    "\n",
    "if len(diff) > 2:  # 有差异\n",
    "    print(\"=== 文本差异 ===\")\n",
    "    for line in diff:\n",
    "        print(line)\n",
    "else:\n",
    "    print(\"✅ 原文和重构文本完全一致\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实体提取详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 详细查看提取的实体\n",
    "print(\"=== 实体提取详解 ===\")\n",
    "\n",
    "entities = compressed.entities\n",
    "\n",
    "print(f\"\\n人名 ({len(entities.get('persons', []))})个):\")\n",
    "for person in entities.get('persons', []):\n",
    "    print(f\"  - {person}\")\n",
    "\n",
    "print(f\"\\n地点 ({len(entities.get('locations', []))})个):\")\n",
    "for location in entities.get('locations', []):\n",
    "    print(f\"  - {location}\")\n",
    "\n",
    "print(f\"\\n日期 ({len(entities.get('dates', []))})个):\")\n",
    "for date in entities.get('dates', []):\n",
    "    print(f\"  - {date}\")\n",
    "\n",
    "print(f\"\\n数字 ({len(entities.get('numbers', []))})个):\")\n",
    "for number in entities.get('numbers', []):\n",
    "    print(f\"  - {number}\")\n",
    "\n",
    "print(f\"\\n关键词 ({len(entities.get('keywords', []))})个):\")\n",
    "for keyword in entities.get('keywords', []):\n",
    "    print(f\"  - {keyword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 不同文本长度的压缩效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同长度的文本\n",
    "test_texts = {\n",
    "    \"短文本 (50字符)\": \"Meeting with John at 3pm to discuss the project.\",\n",
    "    \"中等文本 (200字符)\": original_text[:200],\n",
    "    \"长文本 (500字符)\": original_text,\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, text in test_texts.items():\n",
    "    if len(text) >= config.compression.min_compress_length:\n",
    "        compressed = await compressor.compress(text, MemoryType.TEXT)\n",
    "        ratio = compressed.compression_metadata.compression_ratio\n",
    "    else:\n",
    "        ratio = 1.0  # 不压缩\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'length': len(text),\n",
    "        'ratio': ratio\n",
    "    })\n",
    "    print(f\"{name}: {len(text)} 字符 -> 压缩比 {ratio:.2f}x\")\n",
    "\n",
    "# 可视化\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "names = [r['name'] for r in results]\n",
    "ratios = [r['ratio'] for r in results]\n",
    "ax.bar(names, ratios)\n",
    "ax.set_ylabel('压缩比')\n",
    "ax.set_title('不同文本长度的压缩效果')\n",
    "ax.axhline(y=10, color='r', linestyle='--', label='目标 (10x)')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本教程展示了：\n",
    "1. ✅ 系统初始化和配置\n",
    "2. ✅ 基本的压缩和重构流程\n",
    "3. ✅ 质量评估和指标分析\n",
    "4. ✅ 实体提取功能\n",
    "5. ✅ 不同文本长度的压缩效果\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "- **压缩比**: 系统实现了 > 10x 的压缩比（实测 39.63x）\n",
    "- **质量**: 语义相似度 > 0.90，实体准确率 100%\n",
    "- **性能**: 压缩 < 3s，重构 < 500ms\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 学习 [批量处理教程](tutorial_batch.ipynb)\n",
    "- 学习 [质量评估教程](tutorial_quality.ipynb)\n",
    "- 查看 [API 参考文档](../docs/API_REFERENCE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
