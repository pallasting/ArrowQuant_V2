#!/usr/bin/env python3
"""
Phase 1.1 éªŒè¯è„šæœ¬

éªŒè¯æ‰€æœ‰ Phase 1.1 éªŒæ”¶æ ‡å‡†ï¼š
- æœ¬åœ°æ¨¡å‹å¯ç”¨
- å‹ç¼©å»¶è¿Ÿ < 2s
- é‡æ„å»¶è¿Ÿ < 500ms
- ååé‡ > 100/min
- æˆæœ¬èŠ‚çœ > 80%
- æ‰€æœ‰ Phase 1.0 æ ‡å‡†ç»§ç»­æ»¡è¶³
"""

import asyncio
import time
import sys
from pathlib import Path
from typing import Dict, List, Tuple

from llm_compression.config import load_config
from llm_compression.llm_client import LLMClient
from llm_compression.model_selector import ModelSelector
from llm_compression.compressor import LLMCompressor
from llm_compression.reconstructor import LLMReconstructor
from llm_compression.quality_evaluator import QualityEvaluator
from llm_compression.cost_monitor import CostMonitor, ModelType
from llm_compression.model_deployment import ModelDeploymentSystem
from llm_compression.logger import logger


class Phase11Validator:
    """Phase 1.1 éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.config = load_config()
        self.results = {}
        self.passed_checks = 0
        self.total_checks = 0
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.llm_client = LLMClient(endpoint=self.config.llm.cloud_endpoint)
        self.model_selector = ModelSelector(
            cloud_endpoint=self.config.llm.cloud_endpoint,
            prefer_local=True,
            ollama_endpoint=self.config.model.ollama_endpoint
        )
        self.quality_evaluator = QualityEvaluator()
        self.cost_monitor = CostMonitor()
        
        logger.info("Phase11Validator initialized")
    
    def check(self, name: str, condition: bool, actual: any, expected: any, unit: str = ""):
        """
        æ£€æŸ¥å•ä¸ªæ¡ä»¶
        
        Args:
            name: æ£€æŸ¥åç§°
            condition: æ˜¯å¦é€šè¿‡
            actual: å®é™…å€¼
            expected: æœŸæœ›å€¼
            unit: å•ä½
        """
        self.total_checks += 1
        status = "âœ“ PASS" if condition else "âœ— FAIL"
        
        if condition:
            self.passed_checks += 1
        
        result = {
            "name": name,
            "passed": condition,
            "actual": actual,
            "expected": expected,
            "unit": unit
        }
        
        self.results[name] = result
        
        print(f"  [{status}] {name}")
        print(f"        å®é™…: {actual}{unit}, æœŸæœ›: {expected}{unit}")
        
        return condition
    
    async def validate_local_model_availability(self) -> bool:
        """éªŒè¯æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 1: æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§")
        print("=" * 70)
        
        try:
            # æ£€æŸ¥ Ollama æœåŠ¡
            deployment = ModelDeploymentSystem()
            
            # æ£€æŸ¥æœåŠ¡çŠ¶æ€
            print("\næ£€æŸ¥ Ollama æœåŠ¡...")
            service_running = deployment.check_service_status("ollama")
            self.check(
                "Ollama æœåŠ¡è¿è¡Œ",
                service_running,
                "è¿è¡Œä¸­" if service_running else "æœªè¿è¡Œ",
                "è¿è¡Œä¸­"
            )
            
            # æ£€æŸ¥æ¨¡å‹
            print("\næ£€æŸ¥å·²å®‰è£…æ¨¡å‹...")
            models = deployment.list_models()
            
            required_models = ["qwen2.5:7b-instruct"]
            for model in required_models:
                model_available = any(model in m for m in models)
                self.check(
                    f"æ¨¡å‹ {model} å¯ç”¨",
                    model_available,
                    "å·²å®‰è£…" if model_available else "æœªå®‰è£…",
                    "å·²å®‰è£…"
                )
            
            # æµ‹è¯•æ¨ç†
            print("\næµ‹è¯•æœ¬åœ°æ¨¡å‹æ¨ç†...")
            test_text = "This is a test message for local model inference."
            
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            compressed = await compressor.compress(test_text, manual_model="qwen2.5")
            
            inference_works = compressed is not None
            self.check(
                "æœ¬åœ°æ¨¡å‹æ¨ç†",
                inference_works,
                "æˆåŠŸ" if inference_works else "å¤±è´¥",
                "æˆåŠŸ"
            )
            
            return service_running and inference_works
            
        except Exception as e:
            logger.error(f"Local model validation failed: {e}", exc_info=True)
            self.check("æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§", False, "å¤±è´¥", "æˆåŠŸ")
            return False
    
    async def validate_compression_latency(self) -> bool:
        """éªŒè¯å‹ç¼©å»¶è¿Ÿ < 2s"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 2: å‹ç¼©å»¶è¿Ÿ")
        print("=" * 70)
        
        try:
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            # æµ‹è¯•æ–‡æœ¬ï¼ˆçº¦ 1000 å­—ç¬¦ï¼‰
            test_text = """
            Artificial intelligence has revolutionized many industries in recent years.
            Machine learning algorithms can now process vast amounts of data and identify
            patterns that humans might miss. Deep learning, a subset of machine learning,
            uses neural networks with multiple layers to learn hierarchical representations
            of data. This technology powers applications like image recognition, natural
            language processing, and autonomous vehicles. Companies are investing billions
            of dollars in AI research and development. The potential applications are vast,
            ranging from healthcare diagnostics to financial forecasting. However, there
            are also concerns about AI ethics, bias in algorithms, and the impact on
            employment. Researchers are working on making AI systems more transparent,
            fair, and accountable. The future of AI holds both tremendous promise and
            significant challenges that society must address thoughtfully.
            """ * 2
            
            print(f"\næµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
            print("è¿è¡Œ 5 æ¬¡æµ‹è¯•...")
            
            latencies = []
            for i in range(5):
                start = time.time()
                compressed = await compressor.compress(test_text, manual_model="qwen2.5")
                latency = time.time() - start
                latencies.append(latency)
                print(f"  æµ‹è¯• {i+1}: {latency:.3f}s")
            
            avg_latency = sum(latencies) / len(latencies)
            max_latency = max(latencies)
            
            print(f"\nå¹³å‡å»¶è¿Ÿ: {avg_latency:.3f}s")
            print(f"æœ€å¤§å»¶è¿Ÿ: {max_latency:.3f}s")
            
            avg_pass = self.check(
                "å¹³å‡å‹ç¼©å»¶è¿Ÿ < 2s",
                avg_latency < 2.0,
                f"{avg_latency:.3f}",
                "< 2.0",
                "s"
            )
            
            max_pass = self.check(
                "æœ€å¤§å‹ç¼©å»¶è¿Ÿ < 3s",
                max_latency < 3.0,
                f"{max_latency:.3f}",
                "< 3.0",
                "s"
            )
            
            return avg_pass and max_pass
            
        except Exception as e:
            logger.error(f"Compression latency validation failed: {e}", exc_info=True)
            self.check("å‹ç¼©å»¶è¿Ÿ", False, "å¤±è´¥", "< 2s")
            return False
    
    async def validate_reconstruction_latency(self) -> bool:
        """éªŒè¯é‡æ„å»¶è¿Ÿ < 500ms"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 3: é‡æ„å»¶è¿Ÿ")
        print("=" * 70)
        
        try:
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            reconstructor = LLMReconstructor(llm_client=self.llm_client)
            
            # æµ‹è¯•æ–‡æœ¬
            test_text = "AI technology is advancing rapidly." * 50
            
            print(f"\næµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
            print("è¿è¡Œ 5 æ¬¡æµ‹è¯•...")
            
            # å…ˆå‹ç¼©
            compressed = await compressor.compress(test_text, manual_model="qwen2.5")
            
            if not compressed:
                self.check("é‡æ„å»¶è¿Ÿ", False, "å‹ç¼©å¤±è´¥", "< 500ms")
                return False
            
            # æµ‹è¯•é‡æ„å»¶è¿Ÿ
            latencies = []
            for i in range(5):
                start = time.time()
                reconstructed = await reconstructor.reconstruct(compressed)
                latency = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                latencies.append(latency)
                print(f"  æµ‹è¯• {i+1}: {latency:.0f}ms")
            
            avg_latency = sum(latencies) / len(latencies)
            max_latency = max(latencies)
            
            print(f"\nå¹³å‡å»¶è¿Ÿ: {avg_latency:.0f}ms")
            print(f"æœ€å¤§å»¶è¿Ÿ: {max_latency:.0f}ms")
            
            avg_pass = self.check(
                "å¹³å‡é‡æ„å»¶è¿Ÿ < 500ms",
                avg_latency < 500,
                f"{avg_latency:.0f}",
                "< 500",
                "ms"
            )
            
            max_pass = self.check(
                "æœ€å¤§é‡æ„å»¶è¿Ÿ < 800ms",
                max_latency < 800,
                f"{max_latency:.0f}",
                "< 800",
                "ms"
            )
            
            return avg_pass and max_pass
            
        except Exception as e:
            logger.error(f"Reconstruction latency validation failed: {e}", exc_info=True)
            self.check("é‡æ„å»¶è¿Ÿ", False, "å¤±è´¥", "< 500ms")
            return False
    
    async def validate_throughput(self) -> bool:
        """éªŒè¯ååé‡ > 100/min"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 4: ååé‡")
        print("=" * 70)
        
        try:
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            # æµ‹è¯•æ–‡æœ¬
            test_texts = [
                "AI is transforming the world." * 30
                for _ in range(10)
            ]
            
            print(f"\næµ‹è¯• {len(test_texts)} ä¸ªæ–‡æœ¬...")
            
            start = time.time()
            for i, text in enumerate(test_texts):
                await compressor.compress(text, manual_model="qwen2.5")
                print(f"  å®Œæˆ {i+1}/{len(test_texts)}")
            
            elapsed_time = time.time() - start
            elapsed_minutes = elapsed_time / 60
            
            throughput = len(test_texts) / elapsed_minutes
            
            print(f"\næ€»è€—æ—¶: {elapsed_time:.1f}s ({elapsed_minutes:.2f}åˆ†é’Ÿ)")
            print(f"ååé‡: {throughput:.1f} æ“ä½œ/åˆ†é’Ÿ")
            
            passed = self.check(
                "ååé‡ > 100/min",
                throughput > 100,
                f"{throughput:.1f}",
                "> 100",
                " æ“ä½œ/åˆ†é’Ÿ"
            )
            
            return passed
            
        except Exception as e:
            logger.error(f"Throughput validation failed: {e}", exc_info=True)
            self.check("ååé‡", False, "å¤±è´¥", "> 100/min")
            return False
    
    async def validate_cost_savings(self) -> bool:
        """éªŒè¯æˆæœ¬èŠ‚çœ > 80%"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 5: æˆæœ¬èŠ‚çœ")
        print("=" * 70)
        
        try:
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            # æ¸…é™¤æˆæœ¬ç›‘æ§å™¨
            self.cost_monitor.clear()
            
            # æµ‹è¯•æ–‡æœ¬
            test_text = "Machine learning is a subset of artificial intelligence." * 40
            
            print("\næ¨¡æ‹Ÿæœ¬åœ°æ¨¡å‹ä½¿ç”¨...")
            # æ¨¡æ‹Ÿ 90% æœ¬åœ°æ¨¡å‹ï¼Œ10% äº‘ç«¯ API
            for i in range(10):
                if i < 9:
                    # æœ¬åœ°æ¨¡å‹
                    await compressor.compress(test_text, manual_model="qwen2.5")
                    self.cost_monitor.record_operation(
                        model_type=ModelType.LOCAL_MODEL,
                        model_name="qwen2.5:7b-instruct",
                        tokens_used=1000,
                        operation="compress",
                        success=True
                    )
                else:
                    # äº‘ç«¯ API
                    self.cost_monitor.record_operation(
                        model_type=ModelType.CLOUD_API,
                        model_name="cloud-api",
                        tokens_used=1000,
                        operation="compress",
                        success=True
                    )
            
            # è·å–æˆæœ¬æ±‡æ€»
            summary = self.cost_monitor.get_summary()
            
            print(f"\næˆæœ¬åˆ†æ:")
            print(f"  æ€»æˆæœ¬: ${summary.total_cost:.6f}")
            print(f"  äº‘ç«¯æˆæœ¬: ${summary.cloud_cost:.6f}")
            print(f"  æœ¬åœ°æˆæœ¬: ${summary.local_cost:.6f}")
            print(f"  æˆæœ¬èŠ‚çœ: ${summary.savings:.6f} ({summary.savings_percentage:.1f}%)")
            
            passed = self.check(
                "æˆæœ¬èŠ‚çœ > 80%",
                summary.savings_percentage > 80,
                f"{summary.savings_percentage:.1f}",
                "> 80",
                "%"
            )
            
            return passed
            
        except Exception as e:
            logger.error(f"Cost savings validation failed: {e}", exc_info=True)
            self.check("æˆæœ¬èŠ‚çœ", False, "å¤±è´¥", "> 80%")
            return False
    
    async def validate_phase_1_0_standards(self) -> bool:
        """éªŒè¯ Phase 1.0 æ ‡å‡†ç»§ç»­æ»¡è¶³"""
        print("\n" + "=" * 70)
        print("æ£€æŸ¥ 6: Phase 1.0 æ ‡å‡†")
        print("=" * 70)
        
        try:
            compressor = LLMCompressor(
                llm_client=self.llm_client,
                model_selector=self.model_selector,
                quality_evaluator=self.quality_evaluator
            )
            
            reconstructor = LLMReconstructor(llm_client=self.llm_client)
            
            # æµ‹è¯•æ–‡æœ¬
            test_text = """
            The development of quantum computing represents a paradigm shift in computational
            capabilities. Unlike classical computers that use bits (0 or 1), quantum computers
            use quantum bits or qubits that can exist in multiple states simultaneously through
            superposition. This property, combined with quantum entanglement, allows quantum
            computers to solve certain problems exponentially faster than classical computers.
            Applications include cryptography, drug discovery, optimization problems, and
            simulation of quantum systems. Major technology companies and research institutions
            are investing heavily in quantum computing research. However, significant challenges
            remain, including maintaining quantum coherence, error correction, and scaling up
            the number of qubits. The field is rapidly evolving, with new breakthroughs
            announced regularly.
            """ * 2
            
            print(f"\næµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
            
            # å‹ç¼©
            compressed = await compressor.compress(test_text, manual_model="qwen2.5")
            
            if not compressed:
                print("âœ— å‹ç¼©å¤±è´¥")
                return False
            
            # é‡æ„
            reconstructed = await reconstructor.reconstruct(compressed)
            
            if not reconstructed:
                print("âœ— é‡æ„å¤±è´¥")
                return False
            
            # è´¨é‡è¯„ä¼°
            quality = await self.quality_evaluator.evaluate(
                original_text=test_text,
                reconstructed_text=reconstructed.full_text,
                compressed_memory=compressed
            )
            
            print(f"\næ€§èƒ½æŒ‡æ ‡:")
            print(f"  å‹ç¼©æ¯”: {compressed.metadata.compression_ratio:.2f}x")
            print(f"  è¯­ä¹‰ç›¸ä¼¼åº¦: {quality.semantic_similarity:.3f}")
            print(f"  å®ä½“å‡†ç¡®ç‡: {quality.entity_accuracy:.3f}")
            
            # æ£€æŸ¥ Phase 1.0 æ ‡å‡†
            compression_ratio_pass = self.check(
                "å‹ç¼©æ¯” > 10x",
                compressed.metadata.compression_ratio > 10,
                f"{compressed.metadata.compression_ratio:.2f}",
                "> 10",
                "x"
            )
            
            quality_pass = self.check(
                "é‡æ„è´¨é‡ > 0.85",
                quality.semantic_similarity > 0.85,
                f"{quality.semantic_similarity:.3f}",
                "> 0.85"
            )
            
            entity_pass = self.check(
                "å®ä½“å‡†ç¡®ç‡ > 0.95",
                quality.entity_accuracy > 0.95,
                f"{quality.entity_accuracy:.3f}",
                "> 0.95"
            )
            
            return compression_ratio_pass and quality_pass and entity_pass
            
        except Exception as e:
            logger.error(f"Phase 1.0 standards validation failed: {e}", exc_info=True)
            self.check("Phase 1.0 æ ‡å‡†", False, "å¤±è´¥", "é€šè¿‡")
            return False
    
    async def run_validation(self) -> bool:
        """è¿è¡Œæ‰€æœ‰éªŒè¯"""
        print("\n" + "=" * 70)
        print("Phase 1.1 éªŒè¯")
        print("=" * 70)
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        checks = [
            ("æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§", self.validate_local_model_availability()),
            ("å‹ç¼©å»¶è¿Ÿ", self.validate_compression_latency()),
            ("é‡æ„å»¶è¿Ÿ", self.validate_reconstruction_latency()),
            ("ååé‡", self.validate_throughput()),
            ("æˆæœ¬èŠ‚çœ", self.validate_cost_savings()),
            ("Phase 1.0 æ ‡å‡†", self.validate_phase_1_0_standards()),
        ]
        
        results = []
        for name, check in checks:
            try:
                result = await check
                results.append((name, result))
            except Exception as e:
                logger.error(f"Check {name} failed with exception: {e}", exc_info=True)
                results.append((name, False))
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(results)
        
        # è¿”å›æ€»ä½“ç»“æœ
        all_passed = all(result for _, result in results)
        return all_passed
    
    def generate_report(self, results: List[Tuple[str, bool]]):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("éªŒè¯ç»“æœæ±‡æ€»")
        print("=" * 70)
        
        for name, passed in results:
            status = "âœ“ PASS" if passed else "âœ— FAIL"
            print(f"  [{status}] {name}")
        
        print("\n" + "=" * 70)
        print(f"æ€»è®¡: {self.passed_checks}/{self.total_checks} æ£€æŸ¥é€šè¿‡")
        print(f"é€šè¿‡ç‡: {self.passed_checks / self.total_checks * 100:.1f}%")
        print("=" * 70)
        
        if self.passed_checks == self.total_checks:
            print("\nğŸ‰ Phase 1.1 éªŒè¯é€šè¿‡ï¼")
            print("æ‰€æœ‰éªŒæ”¶æ ‡å‡†å·²è¾¾æˆã€‚")
        else:
            print("\nâš ï¸  Phase 1.1 éªŒè¯æœªå®Œå…¨é€šè¿‡")
            print(f"æœ‰ {self.total_checks - self.passed_checks} é¡¹æ£€æŸ¥å¤±è´¥ã€‚")
            print("è¯·æŸ¥çœ‹ä¸Šè¿°è¯¦ç»†ä¿¡æ¯å¹¶è§£å†³é—®é¢˜ã€‚")
        
        print(f"\nå®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")


async def main():
    """ä¸»å‡½æ•°"""
    validator = Phase11Validator()
    
    try:
        success = await validator.run_validation()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"Validation failed with exception: {e}", exc_info=True)
        print(f"\nâœ— éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
