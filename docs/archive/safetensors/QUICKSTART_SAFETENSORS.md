# SafeTensors é‡åŒ–å¿«é€Ÿå…¥é—¨

## 5 åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: æ„å»ºåº“ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰

```bash
cd ai_os_diffusion/arrow_quant_v2
maturin develop --release
```

ç­‰å¾…ç¼–è¯‘å®Œæˆï¼ˆçº¦ 2-5 åˆ†é’Ÿï¼‰ã€‚

### æ­¥éª¤ 2: é‡åŒ–ä½ çš„æ¨¡å‹

```bash
python examples/quantize_from_safetensors.py \
    --input J:\dream-7b \
    --output F:\models\dream-7b-int4 \
    --bit-width 4 \
    --profile local
```

### æ­¥éª¤ 3: æŸ¥çœ‹ç»“æœ

é‡åŒ–å®Œæˆåï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```
==============================================================
Quantization complete!
==============================================================

Results:
  Output path: F:\models\dream-7b-int4
  Compression ratio: 7.85x
  Cosine similarity: 0.8923
  Model size: 1234.56 MB
  Quantization time: 123.45s
  Modality: text

==============================================================
Done!
==============================================================
```

## Python API ä½¿ç”¨

```python
from arrow_quant_v2 import ArrowQuantV2, DiffusionQuantConfig

# åˆ›å»ºé‡åŒ–å™¨
quantizer = ArrowQuantV2(mode="diffusion")

# ä½¿ç”¨é¢„è®¾é…ç½®
config = DiffusionQuantConfig.from_profile("local")

# é‡åŒ–æ¨¡å‹
result = quantizer.quantize_from_safetensors(
    safetensors_path="J:\\dream-7b",
    output_path="F:\\models\\dream-7b-int4",
    config=config
)

print(f"å®Œæˆï¼å‹ç¼©æ¯”: {result['compression_ratio']:.2f}x")
```

## é…ç½®é€‰é¡¹

### é¢„è®¾é…ç½®

```bash
# Edgeï¼ˆè¾¹ç¼˜è®¾å¤‡ï¼‰- INT2ï¼Œæœ€å¤§å‹ç¼©
--profile edge --bit-width 2

# Localï¼ˆæœ¬åœ°è®¾å¤‡ï¼‰- INT4ï¼Œå¹³è¡¡æ€§èƒ½
--profile local --bit-width 4

# Cloudï¼ˆäº‘ç«¯ï¼‰- INT8ï¼Œæœ€é«˜è´¨é‡
--profile cloud --bit-width 8
```

### è‡ªå®šä¹‰é…ç½®

```python
config = DiffusionQuantConfig(
    bit_width=4,              # 2, 4, æˆ– 8
    modality="text",          # text, code, image, audio
    num_time_groups=10,       # æ—¶é—´ç»„æ•°é‡
    group_size=128,           # åˆ†ç»„å¤§å°
    min_accuracy=0.85,        # æœ€å°ç²¾åº¦é˜ˆå€¼
    enable_time_aware=True,   # å¯ç”¨æ—¶é—´æ„ŸçŸ¥é‡åŒ–
    enable_spatial=True,      # å¯ç”¨ç©ºé—´é‡åŒ–
)
```

## è¿›åº¦ç›‘æ§

```python
def progress_callback(message: str, progress: float):
    print(f"[{progress*100:.1f}%] {message}")

result = quantizer.quantize_from_safetensors(
    safetensors_path="J:\\dream-7b",
    output_path="F:\\models\\dream-7b-int4",
    config=config,
    progress_callback=progress_callback
)
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
[10.0%] Converting SafeTensors to Parquet format...
[40.0%] SafeTensors conversion complete
[45.0%] Initializing quantization orchestrator...
[50.0%] Orchestrator initialized
[55.0%] Quantizing model layers...
[95.0%] Quantization complete
[100.0%] Cleanup complete
```

## éªŒè¯è´¨é‡

```bash
python examples/quantize_from_safetensors.py \
    --input J:\dream-7b \
    --output F:\models\dream-7b-int4 \
    --bit-width 4 \
    --validate
```

ä¼šæ˜¾ç¤ºè¯¦ç»†çš„è´¨é‡æŠ¥å‘Šï¼š

```
==============================================================
Validating quantization quality...
==============================================================

Validation results:
  Overall cosine similarity: 0.8923
  Compression ratio: 7.85x

  Per-layer accuracy (top 5 worst):
    model.layers.0.weight: 0.8234
    model.layers.1.weight: 0.8456
    model.layers.2.weight: 0.8567
    model.layers.3.weight: 0.8678
    model.layers.4.weight: 0.8789
```

## æ”¯æŒçš„æ¨¡å‹æ ¼å¼

âœ… å•æ–‡ä»¶ SafeTensors
```
model.safetensors
```

âœ… åˆ†ç‰‡ SafeTensors
```
model.safetensors.index.json
model-00001-of-00005.safetensors
model-00002-of-00005.safetensors
...
```

âœ… ç›®å½•è¾“å…¥ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
```
J:\dream-7b\
â”œâ”€â”€ model.safetensors.index.json
â”œâ”€â”€ model-00001-of-00005.safetensors
â”œâ”€â”€ model-00002-of-00005.safetensors
â””â”€â”€ ...
```

## å¸¸è§é—®é¢˜

### Q: æ„å»ºå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

ç¡®ä¿å®‰è£…äº† Rust å·¥å…·é“¾ï¼š
```bash
# å®‰è£… Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# å®‰è£… maturin
pip install maturin
```

### Q: é‡åŒ–éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

å–å†³äºæ¨¡å‹å¤§å°ï¼š
- 7B æ¨¡å‹: çº¦ 2-5 åˆ†é’Ÿ
- 13B æ¨¡å‹: çº¦ 5-10 åˆ†é’Ÿ
- 70B æ¨¡å‹: çº¦ 20-40 åˆ†é’Ÿ

### Q: éœ€è¦å¤šå°‘å†…å­˜ï¼Ÿ

- **å¹¶è¡Œæ¨¡å¼**ï¼ˆé»˜è®¤ï¼‰: çº¦ 2x æ¨¡å‹å¤§å°
- **æµå¼æ¨¡å¼**: çº¦ 1.2x æ¨¡å‹å¤§å°

å¯ç”¨æµå¼æ¨¡å¼ï¼š
```python
config.enable_streaming = True
```

### Q: å¦‚ä½•é€‰æ‹© bit-widthï¼Ÿ

- **INT2**: æœ€å¤§å‹ç¼©ï¼ˆ~8xï¼‰ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡
- **INT4**: å¹³è¡¡æ€§èƒ½ï¼ˆ~4xï¼‰ï¼Œæ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯
- **INT8**: æœ€é«˜è´¨é‡ï¼ˆ~2xï¼‰ï¼Œé€‚åˆäº‘ç«¯éƒ¨ç½²

### Q: é‡åŒ–åç²¾åº¦ä¸‹é™å¤šå°‘ï¼Ÿ

å…¸å‹å€¼ï¼š
- INT2: ä½™å¼¦ç›¸ä¼¼åº¦ ~0.75-0.85
- INT4: ä½™å¼¦ç›¸ä¼¼åº¦ ~0.85-0.92
- INT8: ä½™å¼¦ç›¸ä¼¼åº¦ ~0.95-0.98

### Q: æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿ

æ‰€æœ‰ SafeTensors æ ¼å¼çš„æ‰©æ•£æ¨¡å‹ï¼š
- æ–‡æœ¬æ‰©æ•£æ¨¡å‹ï¼ˆMDLM, SEDDï¼‰
- ä»£ç ç”Ÿæˆæ¨¡å‹
- å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆDiT, Stable Diffusionï¼‰
- éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆWaveGradï¼‰

## æ•…éšœæ’é™¤

### é”™è¯¯: "Model not found"

æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š
```python
from pathlib import Path
print(Path("J:\\dream-7b").exists())
```

### é”™è¯¯: "Quantization failed"

å°è¯•é™ä½ç²¾åº¦è¦æ±‚ï¼š
```python
config.min_accuracy = 0.70  # é™ä½é˜ˆå€¼
config.fail_fast = False    # å¯ç”¨è‡ªåŠ¨é™çº§
```

### é”™è¯¯: "Out of memory"

å¯ç”¨æµå¼æ¨¡å¼ï¼š
```python
config.enable_streaming = True
```

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯»å®Œæ•´æ–‡æ¡£: `SAFETENSORS_INTEGRATION_COMPLETE.md`
- ğŸ§ª è¿è¡Œæµ‹è¯•: `pytest tests/test_safetensors_quantization.py -v`
- ğŸ”§ æŸ¥çœ‹ç¤ºä¾‹: `examples/quantize_from_safetensors.py`
- ğŸ“Š æ€§èƒ½åŸºå‡†: `benches/README.md`

## è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹ `SAFETENSORS_INTEGRATION_STATUS.md`
2. è¿è¡Œè¯Šæ–­: `python examples/test_safetensors_integration.py J:\dream-7b`
3. æŸ¥çœ‹æ—¥å¿—: é‡åŒ–è¿‡ç¨‹ä¼šè¾“å‡ºè¯¦ç»†æ—¥å¿—

ç¥é‡åŒ–æ„‰å¿«ï¼ğŸš€
