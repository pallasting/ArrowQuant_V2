# å‘é‡åŒ–æ¨¡å‹é…ç½®æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: 2026-02-17  
**æŸ¥è¯¢**: ç”¨æˆ·è¾“å…¥åˆ°å‘é‡åŒ–è½¬æ¢ä½¿ç”¨çš„æ¨¡å‹åŠç¡¬ä»¶è¦æ±‚

---

## ğŸ“Š å½“å‰é…ç½®

### ä½¿ç”¨çš„æ¨¡å‹

**æ¨¡å‹åç§°**: `sentence-transformers/all-MiniLM-L6-v2`

**ä½ç½®**:
- `llm_compression/compressor.py` (ç¬¬ 147 è¡Œ)
- `llm_compression/quality_evaluator.py` (ç¬¬ 54 è¡Œ)

**æ¨¡å‹å‚æ•°**:
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(
    "sentence-transformers/all-MiniLM-L6-v2",
    device='cpu'  # å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆAMD ROCm å…¼å®¹æ€§ï¼‰
)
```

### æ¨¡å‹ç‰¹æ€§

| ç‰¹æ€§ | å€¼ |
|------|-----|
| **å‘é‡ç»´åº¦** | 384 |
| **æœ€å¤§åºåˆ—é•¿åº¦** | 256 tokens |
| **æ¨¡å‹å¤§å°** | ~80 MB |
| **å‚æ•°é‡** | ~22M |
| **è¯­è¨€æ”¯æŒ** | è‹±æ–‡ä¸ºä¸» |
| **æ¨ç†é€Ÿåº¦** | å¿«ï¼ˆ~1000 å¥/ç§’ on CPUï¼‰ |

---

## ğŸ’» ç¡¬ä»¶è¦æ±‚

### æœ€ä½é…ç½®

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| **CPU** | 2 æ ¸å¿ƒ |
| **å†…å­˜** | 2 GB RAM |
| **å­˜å‚¨** | 500 MBï¼ˆæ¨¡å‹ + ä¾èµ–ï¼‰ |
| **GPU** | ä¸éœ€è¦ï¼ˆCPU æ¨¡å¼ï¼‰ |

### æ¨èé…ç½®

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| **CPU** | 4+ æ ¸å¿ƒ |
| **å†…å­˜** | 4 GB RAM |
| **å­˜å‚¨** | 1 GB |
| **GPU** | å¯é€‰ï¼ˆCUDA/ROCmï¼‰ |

### å½“å‰éƒ¨ç½²é…ç½®

**è¿è¡Œæ¨¡å¼**: CPU only
- **åŸå› **: AMD ROCm å…¼å®¹æ€§é—®é¢˜
- **æ€§èƒ½**: è¶³å¤Ÿå¿«ï¼ˆembedding è®¡ç®— < 100msï¼‰
- **é¦–æ¬¡åŠ è½½**: ~8 ç§’ï¼ˆæ¨¡å‹ä¸‹è½½ + åˆå§‹åŒ–ï¼‰

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### 1. æ‡’åŠ è½½æœºåˆ¶

```python
@property
def embedding_model(self):
    """Lazy load embedding model"""
    if self._embedding_model is None:
        import os
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # å›½å†…é•œåƒ
        
        from sentence_transformers import SentenceTransformer
        self._embedding_model = SentenceTransformer(
            "sentence-transformers/all-MiniLM-L6-v2",
            device='cpu'
        )
    return self._embedding_model
```

**ä¼˜åŠ¿**:
- åªåœ¨éœ€è¦æ—¶åŠ è½½ï¼ˆèŠ‚çœå†…å­˜ï¼‰
- é¦–æ¬¡å‹ç¼©æ—¶è‡ªåŠ¨åˆå§‹åŒ–
- å¯é€‰é¢„çƒ­ï¼ˆ`prewarm_embedding=True`ï¼‰

### 2. å‘é‡åŒ–æµç¨‹

```
ç”¨æˆ·è¾“å…¥ (æ–‡æœ¬)
    â†“
Tokenization (åˆ†è¯)
    â†“
BERT Encoding (ç¼–ç )
    â†“
Mean Pooling (æ± åŒ–)
    â†“
Normalization (å½’ä¸€åŒ–)
    â†“
384-dim Vector (å‘é‡)
```

### 3. å­˜å‚¨ä¼˜åŒ–

**å‘é‡å­˜å‚¨æ ¼å¼**: `float16`ï¼ˆåŠç²¾åº¦ï¼‰
- åŸå§‹: 384 Ã— 4 bytes = 1536 bytes
- ä¼˜åŒ–: 384 Ã— 2 bytes = **768 bytes**ï¼ˆèŠ‚çœ 50%ï¼‰

```python
# arrow_storage.py
('embedding', pa.list_(pa.float16()))  # ä½¿ç”¨ float16
```

---

## ğŸŒ å¤šè¯­è¨€æ”¯æŒ

### å½“å‰æ¨¡å‹é™åˆ¶

`all-MiniLM-L6-v2` ä¸»è¦é’ˆå¯¹è‹±æ–‡ä¼˜åŒ–ï¼Œä¸­æ–‡æ”¯æŒæœ‰é™ã€‚

### æ¨èæ›¿ä»£æ–¹æ¡ˆ

#### æ–¹æ¡ˆ 1: å¤šè¯­è¨€æ¨¡å‹ï¼ˆæ¨èï¼‰

```python
embedding_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
```

**ç‰¹æ€§**:
- æ”¯æŒ 50+ è¯­è¨€ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰
- ç»´åº¦: 384ï¼ˆæ— éœ€ä¿®æ”¹ä»£ç ï¼‰
- é€Ÿåº¦: ç•¥æ…¢ï¼ˆ~800 å¥/ç§’ï¼‰
- å¤§å°: ~120 MB

#### æ–¹æ¡ˆ 2: ä¸­æ–‡ä¸“ç”¨æ¨¡å‹

```python
embedding_model = "BAAI/bge-small-zh-v1.5"
```

**ç‰¹æ€§**:
- ä¸“ä¸ºä¸­æ–‡ä¼˜åŒ–
- ç»´åº¦: 512ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
- ä¸­æ–‡åœºæ™¯æ€§èƒ½æœ€ä½³
- å¤§å°: ~100 MB

#### æ–¹æ¡ˆ 3: é«˜æ€§èƒ½æ¨¡å‹

```python
embedding_model = "BAAI/bge-large-zh-v1.5"
```

**ç‰¹æ€§**:
- æœ€é«˜ç²¾åº¦
- ç»´åº¦: 1024
- é€Ÿåº¦: æ…¢ï¼ˆ~100 å¥/ç§’ï¼‰
- å¤§å°: ~1.3 GB
- **ç¡¬ä»¶è¦æ±‚**: 8 GB RAM

---

## âš¡ æ€§èƒ½åŸºå‡†

### CPU æ¨¡å¼ï¼ˆå½“å‰é…ç½®ï¼‰

| æ“ä½œ | å»¶è¿Ÿ |
|------|------|
| æ¨¡å‹åŠ è½½ï¼ˆé¦–æ¬¡ï¼‰ | ~8 ç§’ |
| å•å¥å‘é‡åŒ– | ~10-50 ms |
| æ‰¹é‡å‘é‡åŒ–ï¼ˆ32 å¥ï¼‰ | ~200 ms |
| ç›¸ä¼¼åº¦è®¡ç®— | < 1 ms |

### GPU æ¨¡å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰

| æ“ä½œ | å»¶è¿Ÿ |
|------|------|
| æ¨¡å‹åŠ è½½ | ~2 ç§’ |
| å•å¥å‘é‡åŒ– | ~5 ms |
| æ‰¹é‡å‘é‡åŒ–ï¼ˆ32 å¥ï¼‰ | ~20 ms |
| ç›¸ä¼¼åº¦è®¡ç®— | < 0.1 ms |

**æ³¨**: å½“å‰ç³»ç»Ÿå›  AMD ROCm å…¼å®¹æ€§é—®é¢˜ä½¿ç”¨ CPU æ¨¡å¼ã€‚

---

## ğŸ”„ å¦‚ä½•æ›´æ¢æ¨¡å‹

### æ­¥éª¤ 1: ä¿®æ”¹é…ç½®

ç¼–è¾‘ `llm_compression/quality_evaluator.py`:

```python
def __init__(
    self,
    embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",  # æ”¹è¿™é‡Œ
    ...
):
```

ç¼–è¾‘ `llm_compression/compressor.py`:

```python
self._embedding_model = SentenceTransformer(
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",  # æ”¹è¿™é‡Œ
    device='cpu'
)
```

### æ­¥éª¤ 2: æ¸…é™¤ç¼“å­˜

```bash
rm -rf ~/.cache/huggingface/hub/models--sentence-transformers*
```

### æ­¥éª¤ 3: é‡å¯ç³»ç»Ÿ

```bash
# æ¨¡å‹ä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½
python your_script.py
```

---

## ğŸ“¦ ä¾èµ–é¡¹

### Python åŒ…

```txt
sentence-transformers>=2.2.0
torch>=2.0.0
transformers>=4.30.0
```

### å®‰è£…å‘½ä»¤

```bash
pip install sentence-transformers torch
```

### å›½å†…é•œåƒåŠ é€Ÿ

ç³»ç»Ÿå·²é…ç½® HuggingFace é•œåƒï¼š
```python
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—

```python
# quality_evaluator.py
similarity = cosine_similarity(
    embedding_original,
    embedding_reconstructed
)
```

### 2. è®°å¿†æ£€ç´¢

```python
# openclaw_interface.py
def search_memories(query: str, top_k: int = 5):
    query_embedding = compute_embedding(query)
    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢æœ€ç›¸å…³çš„è®°å¿†
```

### 3. å»é‡æ£€æµ‹

```python
# batch_processor.py
def deduplicate(texts: List[str]):
    embeddings = [compute_embedding(t) for t in texts]
    # åŸºäº embedding ç›¸ä¼¼åº¦å»é‡
```

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### 1. é¢„çƒ­æ¨¡å‹ï¼ˆå·²å®ç°ï¼‰

```python
compressor = LLMCompressor(
    llm_client=client,
    model_selector=selector,
    prewarm_embedding=True  # å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
)
```

### 2. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡è®¡ç®— embeddingï¼ˆæ›´å¿«ï¼‰
embeddings = model.encode(texts, batch_size=32)
```

### 3. ç¼“å­˜ Embedding

```python
# ç¼“å­˜å¸¸ç”¨æ–‡æœ¬çš„ embedding
embedding_cache = {}
if text in embedding_cache:
    return embedding_cache[text]
```

---

## ğŸ“Š æ€»ç»“

| é¡¹ç›® | å€¼ |
|------|-----|
| **å½“å‰æ¨¡å‹** | all-MiniLM-L6-v2 |
| **å‘é‡ç»´åº¦** | 384 |
| **è¿è¡Œæ¨¡å¼** | CPU only |
| **å†…å­˜éœ€æ±‚** | 2-4 GB |
| **æ¨ç†é€Ÿåº¦** | 10-50 ms/å¥ |
| **è¯­è¨€æ”¯æŒ** | è‹±æ–‡ä¸ºä¸» |
| **å»ºè®®å‡çº§** | paraphrase-multilingual-MiniLM-L12-v2ï¼ˆå¤šè¯­è¨€ï¼‰ |

**ç»“è®º**: å½“å‰é…ç½®é€‚åˆè‹±æ–‡åœºæ™¯ï¼Œç¡¬ä»¶è¦æ±‚ä½ã€‚å¦‚éœ€ä¸­æ–‡æ”¯æŒï¼Œå»ºè®®åˆ‡æ¢åˆ°å¤šè¯­è¨€æˆ–ä¸­æ–‡ä¸“ç”¨æ¨¡å‹ã€‚
