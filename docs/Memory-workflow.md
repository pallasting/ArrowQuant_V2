完整的数据流：

## 当前实现的完整工作流程

┌─────────────────────────────────────────────────────────────┐
│                    用户输入（CLI）                            │
│                  "What is Python?"                          │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              前端感知模型（Embedding Model）                  │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  sentence-transformers/all-MiniLM-L6-v2              │  │
│  │  • 文本 → 向量 (384维)                                │  │
│  │  • 语义特征提取                                        │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │ query_embedding
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              记忆查询（NetworkNavigator）                     │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  1. 余弦相似度计算（query vs 所有记忆）                │  │
│  │  2. 激活扩散（多跳传播）                               │  │
│  │  3. 排序（激活水平 + 相似度）                          │  │
│  │  4. 返回Top-K记忆                                     │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │ relevant_memories
                         ▼
┌─────────────────────────────────────────────────────────────┐
│            输出生成模型（MultiModalExpressor）                │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  LLM (qwen2.5:3b / gemma3 / llama3.1)               │  │
│  │  • 记忆重构                                           │  │
│  │  • 上下文整合                                         │  │
│  │  • 生成回复                                           │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │ output
                         ▼
┌─────────────────────────────────────────────────────────────┐
│          内部反馈循环（InternalFeedbackSystem）               │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  质量评估（5个维度）:                                   │  │
│  │  • 一致性 (consistency)                               │  │
│  │  • 完整性 (completeness)                              │  │
│  │  • 准确性 (accuracy)                                  │  │
│  │  • 连贯性 (coherence)                                 │  │
│  │  • 整体质量 (overall)                                 │  │
│  │                                                       │  │
│  │  if quality < 0.85:                                  │  │
│  │    → 生成纠正策略                                      │  │
│  │    → 重新生成（最多2次）                               │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │ quality_score
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              学习与记忆更新（ConnectionLearner）              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  Hebbian学习:                                         │  │
│  │  • 共激活记忆 → 连接强化                               │  │
│  │  • 连接强度 = f(共激活, 相似度)                        │  │
│  │  • 成功反馈 → success_count++                         │  │
│  │  • 访问追踪 → access_count++                          │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              对话存储（ConversationMemory）                   │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  1. 压缩对话轮次（LLMCompressor）                      │  │
│  │  2. 创建MemoryPrimitive                               │  │
│  │  3. 添加到记忆网络                                     │  │
│  │  4. 时间戳记录                                         │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│            个性化更新（PersonalizationEngine）                │
│  ┌──────────────────────────────────────────────────────┐  │
│  │  • 提取话题关键词                                      │  │
│  │  • 基于质量更新偏好                                    │  │
│  │  • 风格自适应                                         │  │
│  │  • 偏好衰减                                           │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│                  输出到用户（CLI）                            │
│  "Python is a high-level programming language..."          │
│  📊 Quality: 0.92 | Memories: 3 | Learning: ✅             │
└─────────────────────────────────────────────────────────────┘


## 关键流程细节

### 1. 前端感知（Embedding）

python
# 当前实现
query_embedding = await compressor.get_embedding(user_message)
# → 使用 sentence-transformers/all-MiniLM-L6-v2
# → 输出: 384维向量

# 未来扩展（多模态）
if image:
    image_embedding = await vision_model.encode(image)
if audio:
    audio_embedding = await audio_model.encode(audio)


### 2. 记忆查询（去重+检索）

python
# NetworkNavigator.retrieve()
result = navigator.retrieve(
    query_embedding=query_embedding,
    memory_network=memory_network,
    top_k=5,
    activation_threshold=0.1
)

# 内部流程:
# 1. 计算相似度（余弦）
# 2. 激活扩散（多跳）
# 3. 去重（基于ID）
# 4. 排序（激活+相似度）


### 3. 输出生成

python
# MultiModalExpressor.express_text()
output = await expressor.express_text(
    memories=relevant_memories,
    query=user_message,
    style=personalization.style,
    max_length=500
)

# 使用LLM重构记忆并生成回复


### 4. 内部反馈循环

python
# InternalFeedbackSystem.evaluate()
quality = await feedback.evaluate(
    output=output,
    query=user_message,
    memories=relevant_memories
)

# 如果质量不足
if quality.overall < 0.85:
    correction = feedback.suggest_correction(quality)
    output = apply_correction(...)  # 重新生成


### 5. 学习更新

python
# Hebbian学习
for mem_a, mem_b in pairs(activated_memories):
    learner.hebbian_learning(
        memory_a=mem_a,
        memory_b=mem_b,
        co_activation=1.0
    )

# 成功反馈
if quality.overall >= 0.85:
    for memory in activated_memories:
        memory.record_success()


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


## 🎯 你的理解完全正确！

### 核心流程

输入 → 感知向量化 → 记忆查询 → 输出生成 → 内反馈 → 学习 → 存储
 ↑                                                          ↓
 └────────────────── 持续演化循环 ─────────────────────────┘


### 关键特点

1. 前端模型 = 感知入口（Embedding）
2. 记忆查询 = 去重+激活扩散+排序
3. 输出模型 = 表达工具（LLM）
4. 内反馈 = 质量控制+自我纠正
5. 学习 = Hebbian连接强化

### 未来扩展（多模态）

python
# 当前: 文本 → Embedding → 记忆
# 未来: 
#   文本 → Text Encoder → 记忆
#   图像 → Vision Encoder → 记忆
#   音频 → Audio Encoder → 记忆
#   视频 → Video Encoder → 记忆
# 
# 统一向量空间 → 跨模态检索

