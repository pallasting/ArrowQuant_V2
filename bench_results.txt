=======================================================
  ArrowEngine Performance Benchmark Ã¹ Phase 1
=======================================================
  Model: sentence-transformers/all-MiniLM-L6-v2

--- sentence-transformers Reference ---

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 8289.14it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 1964.55it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 1870.37it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 1679.74it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 2144.69it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 2012.94it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 2344.17it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 2231.61it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 2570.04it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 2472.47it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 2763.35it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 2658.27it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 2165.84it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 2047.29it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 2046.75it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 1341.91it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1254.69it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1117.45it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1170.61it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1151.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1231.45it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1216.51it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1296.87it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1282.79it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1266.75it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1241.96it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1286.74it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1253.29it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1295.23it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1280.18it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1336.75it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1324.25it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1382.09it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1370.27it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1425.48it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1413.84it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1467.03it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1455.08it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1432.31it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1417.45it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1444.67it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1425.02it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1435.96it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1393.16it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1424.70it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1414.50it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1457.05it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1448.46it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1491.26it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1482.61it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 1525.22it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 1516.38it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 1532.86it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 1524.38it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 1552.60it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 1539.80it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 1575.78it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 1566.83it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 1604.49it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 1596.71it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 1634.55it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 1626.74it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 1664.26it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 1651.30it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 1687.15it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 1679.64it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 1715.90it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 1708.19it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 1743.83it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 1719.30it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 1735.45it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 1627.85it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1533.41it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1515.31it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1487.18it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1468.13it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1470.98it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1461.03it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1481.81it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1474.88it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1497.65it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1491.12it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 1514.22it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 1507.76it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1495.53it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1483.32it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1498.91it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1469.51it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1476.50it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1468.30it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1465.17it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1459.00it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1478.21it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1473.79it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1496.31it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1491.99it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1514.41it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1510.21it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1532.77it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1528.53it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1550.86it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1546.68it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 1569.11it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 1565.06it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 1586.46it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 1581.69it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 1596.49it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 1591.67it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 1611.35it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 1606.82it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 1626.46it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 1621.87it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1641.31it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1636.55it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 1655.65it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 1650.95it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 1654.71it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 1646.67it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1652.41it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1646.86it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1639.49it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1616.03it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1562.88it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1547.23it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1536.23it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1528.09it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1519.91it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1515.57it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1526.60it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1515.38it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1510.05it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1499.04it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1513.45it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1510.10it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1526.43it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1523.35it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1539.94it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1536.84it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1553.41it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1550.36it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1566.42it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1563.35it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1579.47it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1576.47it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1592.45it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1589.44it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1605.33it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1602.39it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1618.16it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1612.70it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1627.85it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1624.85it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1640.21it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1637.20it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1638.06it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1634.36it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1648.99it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1645.33it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1660.32it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1657.57it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1664.87it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1661.83it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1655.63it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1641.68it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1642.61it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1637.57it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1649.64it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1646.61it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1656.93it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1654.04it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1668.14it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1665.42it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1673.19it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1669.13it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1664.35it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1659.15it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1670.95it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1668.08it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1648.88it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1640.97it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1606.70it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1597.45it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1602.87it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1597.00it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1604.28it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1597.83it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1606.06it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1603.43it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1612.33it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1609.79it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1622.37it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1620.08it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1632.90it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1630.61it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1643.46it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1641.30it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1653.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1651.80it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1664.87it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1662.78it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1675.70it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1673.74it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1686.76it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1684.75it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1697.81it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1695.83it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1691.34it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
  Load time:         8935.5 ms
  Latency (1 seq):    11.03 ms  (mean of 10)
  Throughput b=32:      704 seq/s  (45.5 ms/batch)

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 6335.81it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 1457.37it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 1387.92it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 1059.84it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1193.37it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1012.87it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 1113.14it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 998.17it/s, Materializing param=embeddings.token_type_embeddings.weight] 
Loading weights:   5%|4         | 5/103 [00:00<00:00, 1088.13it/s, Materializing param=embeddings.word_embeddings.weight]     
Loading weights:   5%|4         | 5/103 [00:00<00:00, 997.88it/s, Materializing param=embeddings.word_embeddings.weight] 
Loading weights:   6%|5         | 6/103 [00:00<00:00, 964.39it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 846.99it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 884.85it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 821.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 785.71it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 692.09it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 670.98it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 640.03it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 670.43it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 646.15it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 669.62it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 650.08it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 660.31it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 627.44it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 645.91it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 629.24it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 654.41it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 640.42it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 651.67it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 638.64it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 651.60it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 638.55it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 661.11it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 630.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 594.78it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 580.07it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 592.66it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 581.40it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 594.68it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 585.13it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 591.47it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 574.24it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 581.03it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 572.31it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 586.53it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 579.53it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 593.80it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 586.41it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 593.73it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 582.67it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 585.98it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 564.39it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 564.42it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 551.34it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 549.82it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 543.40it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 552.51it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 547.09it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 553.47it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 547.71it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 557.60it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 552.75it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 558.27it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 553.28it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 558.35it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 553.89it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 559.33it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 549.17it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 550.91it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 541.81it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 546.54it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 541.59it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 549.84it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 545.64it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 550.32it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 545.18it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 552.76it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 548.65it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 556.98it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 553.36it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 561.94it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 558.35it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 567.03it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 563.78it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 572.62it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 569.63it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 576.11it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 569.79it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 572.69it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 562.92it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 559.73it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 554.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 559.17it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 555.93it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 563.25it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 560.33it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 568.20it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 565.74it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 570.95it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 568.63it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 576.80it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 574.63it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 582.76it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 580.57it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 588.70it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 586.64it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 594.09it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 591.71it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 599.43it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 597.41it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 599.37it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 588.93it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 582.92it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 577.52it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 582.18it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 575.91it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 577.32it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 577.32it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 577.32it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 577.32it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 577.32it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 656.47it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
  Peak memory:          8.9 MB

--- Model Conversion ---
2026-02-18 04:21:55 - llm_compression - INFO - Initialized ModelConverter with config: ConversionConfig(compression='lz4', use_float16=True, extract_tokenizer=True, validate_output=True)
2026-02-18 04:21:55 - llm_compression - INFO - Starting conversion of sentence-transformers/all-MiniLM-L6-v2 to E:\Temp\tmpo5hgorxu\minilm

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 13662.23it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 5974.79it/s, Materializing param=embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/103 [00:00<00:00, 5857.97it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 4917.12it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 4826.59it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 3998.38it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 4117.11it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 3852.40it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 4334.75it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 4105.62it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 4473.92it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 4250.98it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 4528.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 4356.75it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 4611.66it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 4447.24it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 4662.06it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 4501.94it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 3673.41it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 3444.16it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 3258.06it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 3005.30it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 2746.76it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 2695.71it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2834.14it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2791.48it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2924.61it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2883.25it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 3010.55it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 2970.19it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 3089.02it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 3049.85it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 3162.56it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 3121.58it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 3193.50it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 3153.48it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 3249.01it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 3209.88it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 3303.12it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 3265.83it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 3357.23it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 3318.03it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 3170.62it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 2985.95it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2922.59it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2523.25it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2426.50it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2343.35it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2335.10it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2306.18it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2117.64it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2095.98it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2135.87it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2121.55it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2103.50it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2089.73it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2138.26it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2126.11it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2173.82it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2161.57it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2209.70it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2197.90it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2244.29it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2231.87it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2277.08it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2265.26it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2286.71it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2273.70it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2315.25it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2301.96it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2294.76it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2281.55it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2319.13it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2307.24it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2345.32it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2331.63it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2227.25it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2210.36it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2241.21it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2229.86it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2262.03it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2250.43it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2282.05it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2270.84it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2301.62it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2288.42it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2270.15it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2257.93it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2285.97it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2275.09it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2255.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2233.60it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2191.04it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2178.74it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2204.84it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2195.44it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2223.48it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2214.64it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2241.58it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2232.79it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2259.12it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2250.26it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2202.67it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2164.82it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2140.53it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2108.13it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2098.61it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2077.53it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2072.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2059.22it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2076.33it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2067.49it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2086.66it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2077.92it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2040.07it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2030.12it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2047.93it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2039.54it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1999.43it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1971.29it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1979.13it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1968.19it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1941.53it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1924.01it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1913.14it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1900.06it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1909.17it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1899.16it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1884.68it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1874.39it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1886.22it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1880.62it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1898.43it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1893.50it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1884.78it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1877.04it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1893.84it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1889.10it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1907.48it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1902.80it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1920.70it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1915.84it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1933.76it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1928.85it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1895.78it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1879.57it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1881.45it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1872.22it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1885.80it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1880.87it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1896.19it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1891.56it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1907.44it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1902.78it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1870.41it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1851.22it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1800.84it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1789.50it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1798.36it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1792.87it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1804.91it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1800.02it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1814.23it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1810.14it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1824.46it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1820.83it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1835.97it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1832.48it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1847.47it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1843.78it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1858.61it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1854.98it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1828.44it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1817.18it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1827.39it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1823.53it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1837.28it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1832.21it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1846.34it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1843.26it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1857.62it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1854.70it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1840.41it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1834.63it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1835.41it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1822.69it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1829.35it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1824.16it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1837.05it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1834.13it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1847.81it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1845.01it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1858.56it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1855.57it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1869.24it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1866.44it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1879.95it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1877.24it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1884.15it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1881.18it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1894.85it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1892.34it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1905.18it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1902.68it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1917.18it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1914.83it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1909.81it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
2026-02-18 04:22:04 - llm_compression - INFO - Loaded sentence-transformers model
2026-02-18 04:22:04 - llm_compression - INFO - Extracted 103 weight tensors (86.64 MB, 22713216 params)
2026-02-18 04:22:04 - llm_compression - INFO - Optimized weights to float16
2026-02-18 04:22:04 - llm_compression - INFO - Converted to Parquet: E:\Temp\tmpo5hgorxu\minilm\weights.parquet (43.50 MB)
2026-02-18 04:22:04 - llm_compression - INFO - Exported tokenizer to E:\Temp\tmpo5hgorxu\minilm\tokenizer
2026-02-18 04:22:04 - llm_compression - INFO - Generated metadata: E:\Temp\tmpo5hgorxu\minilm\metadata.json
2026-02-18 04:22:06 - llm_compression - INFO - Validation passed: all layers match
2026-02-18 04:22:06 - llm_compression - INFO - Validation: PASSED
2026-02-18 04:22:06 - llm_compression - INFO - Conversion completed successfully in 10.87 s
  Converted: 43.5 MB, ratio 2.0x

--- ArrowEngine ---
2026-02-18 04:22:06 - llm_compression - INFO - Initialized WeightLoader for E:\Temp\tmpo5hgorxu\minilm\weights.parquet
2026-02-18 04:22:06 - llm_compression - INFO - Loaded Arrow table in 105.85ms (memory_map=True)
2026-02-18 04:22:06 - llm_compression - INFO - Loaded 103 layers in 143.22ms
2026-02-18 04:22:06 - llm_compression - INFO - Total parameters: 22,713,216, Memory: 43.32MB
2026-02-18 04:22:06 - llm_compression - INFO - Loaded 103 weight tensors
2026-02-18 04:22:07 - llm_compression - INFO - Loaded Rust tokenizer: tokenizer.json
2026-02-18 04:22:07 - llm_compression - INFO - Initialized FastTokenizer from E:\Temp\tmpo5hgorxu\minilm\tokenizer
2026-02-18 04:22:07 - llm_compression - INFO - Loaded tokenizer with max_length=256
2026-02-18 04:22:07 - llm_compression - INFO - Initialized InferenceCore on cpu: hidden=384, layers=6, heads=12, intermediate=1536
2026-02-18 04:22:07 - llm_compression - INFO - InferenceCore: hidden=384, layers=6, heads=12, intermediate=1536
2026-02-18 04:22:07 - llm_compression - INFO - ArrowEngine loaded in 384.51ms
2026-02-18 04:22:07 - llm_compression - INFO - Model: sentence-transformers/all-MiniLM-L6-v2
2026-02-18 04:22:07 - llm_compression - INFO - Embedding dimension: 384
2026-02-18 04:22:07 - llm_compression - INFO - Device: cpu
  Load time:          384.9 ms
  Latency (1 seq):    35.46 ms  (mean of 10)
  Throughput b=32:       36 seq/s  (891.2 ms/batch)
  Throughput b=100:      36 seq/s  (2781.0 ms/batch)
2026-02-18 04:22:20 - llm_compression - INFO - Initialized WeightLoader for E:\Temp\tmpo5hgorxu\minilm\weights.parquet
2026-02-18 04:22:20 - llm_compression - INFO - Loaded Arrow table in 88.63ms (memory_map=True)
2026-02-18 04:22:20 - llm_compression - INFO - Loaded 103 layers in 131.15ms
2026-02-18 04:22:20 - llm_compression - INFO - Total parameters: 22,713,216, Memory: 43.32MB
2026-02-18 04:22:20 - llm_compression - INFO - Loaded 103 weight tensors
2026-02-18 04:22:20 - llm_compression - INFO - Loaded Rust tokenizer: tokenizer.json
2026-02-18 04:22:20 - llm_compression - INFO - Initialized FastTokenizer from E:\Temp\tmpo5hgorxu\minilm\tokenizer
2026-02-18 04:22:20 - llm_compression - INFO - Loaded tokenizer with max_length=256
2026-02-18 04:22:20 - llm_compression - INFO - Initialized InferenceCore on cpu: hidden=384, layers=6, heads=12, intermediate=1536
2026-02-18 04:22:20 - llm_compression - INFO - InferenceCore: hidden=384, layers=6, heads=12, intermediate=1536
2026-02-18 04:22:20 - llm_compression - INFO - ArrowEngine loaded in 306.17ms
2026-02-18 04:22:20 - llm_compression - INFO - Model: sentence-transformers/all-MiniLM-L6-v2
2026-02-18 04:22:20 - llm_compression - INFO - Embedding dimension: 384
2026-02-18 04:22:20 - llm_compression - INFO - Device: cpu
  Peak memory:         44.8 MB

=======================================================
  COMPARISON SUMMARY
=======================================================
  Metric                            ST      Arrow    Speedup
  -------------------------------------------------------
  Load time (ms)                8935.5      384.9      23.2x
  Latency/seq (ms)               11.03      35.46       0.3x
  Throughput b=32 (seq/s)          704         36       0.1x
  Peak memory (MB)                 8.9       44.8

  Targets:
  [FAIL] Load time < 100ms: 384.9ms
  [FAIL] Latency < 5ms: 35.46ms
  [FAIL] Throughput > 2000 seq/s: 36 seq/s
=======================================================
