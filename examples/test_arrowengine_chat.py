#!/usr/bin/env python3
"""
ArrowEngine Agent-Chat å®é™…ç¯å¢ƒæµ‹è¯•

æµ‹è¯• ArrowEngine åœ¨çœŸå® Agent-Chat ä¼šè¯åœºæ™¯ä¸­çš„è¡¨ç°ã€‚
éªŒè¯ï¼šç²¾åº¦ã€æ€§èƒ½ã€ç¨³å®šæ€§ã€å†…å­˜ä½¿ç”¨ã€‚
"""

import asyncio
import time
import sys
from datetime import datetime
from typing import List, Dict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/memory/Documents/ai-os-memory')

from llm_compression.embedding_provider import get_default_provider
from llm_compression.semantic_indexer import SemanticIndexer
from llm_compression.semantic_index_db import SemanticIndexDB
from llm_compression.arrow_storage import ArrowStorage
from llm_compression.memory_search import MemorySearch, SearchMode
from llm_compression.vector_search import VectorSearch
from llm_compression.background_queue import BackgroundQueue
from llm_compression.logger import logger


class ChatMemorySystem:
    """Chat è®°å¿†ç³»ç»Ÿï¼ˆä½¿ç”¨ ArrowEngineï¼‰"""
    
    def __init__(self, data_dir: str = "./test_chat_data"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.data_dir = data_dir
        
        # åˆå§‹åŒ–ç»„ä»¶
        logger.info("Initializing ArrowEngine-based memory system...")
        self.provider = get_default_provider()
        self.storage = ArrowStorage(f"{data_dir}/memories.parquet")
        self.index_db = SemanticIndexDB(f"{data_dir}/index")
        self.indexer = SemanticIndexer(self.provider, self.storage, self.index_db)
        self.vector_search = VectorSearch(self.provider, self.storage, self.index_db)
        self.memory_search = MemorySearch(self.vector_search, self.storage)
        self.background_queue = BackgroundQueue(self.indexer, batch_size=16)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'memories_added': 0,
            'searches_performed': 0,
            'total_search_time': 0.0,
            'total_index_time': 0.0
        }
        
        logger.info(f"System initialized with {type(self.provider).__name__}")
    
    async def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        await self.background_queue.start()
        logger.info("Background queue started")
    
    async def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        await self.background_queue.stop()
        logger.info("Background queue stopped")
    
    async def add_chat_message(
        self,
        message_id: str,
        role: str,
        content: str,
        metadata: Dict = None
    ):
        """æ·»åŠ èŠå¤©æ¶ˆæ¯åˆ°è®°å¿†"""
        start = time.time()
        
        memory = {
            'memory_id': message_id,
            'category': 'chat',
            'context': f"[{role}] {content}",
            'timestamp': datetime.now(),
            'embedding': None,
            'metadata': metadata or {}
        }
        
        # å¼‚æ­¥ç´¢å¼•ï¼ˆéé˜»å¡ï¼‰
        await self.background_queue.submit(memory)
        
        elapsed = time.time() - start
        self.stats['memories_added'] += 1
        self.stats['total_index_time'] += elapsed
        
        return memory
    
    async def search_relevant_context(
        self,
        query: str,
        top_k: int = 5,
        mode: SearchMode = SearchMode.SEMANTIC
    ) -> List:
        """æœç´¢ç›¸å…³ä¸Šä¸‹æ–‡"""
        start = time.time()
        
        results = self.memory_search.search(
            query=query,
            category="chat",
            mode=mode,
            top_k=top_k
        )
        
        elapsed = time.time() - start
        self.stats['searches_performed'] += 1
        self.stats['total_search_time'] += elapsed
        
        return results
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        avg_search_time = (
            self.stats['total_search_time'] / self.stats['searches_performed']
            if self.stats['searches_performed'] > 0 else 0
        )
        avg_index_time = (
            self.stats['total_index_time'] / self.stats['memories_added']
            if self.stats['memories_added'] > 0 else 0
        )
        
        return {
            **self.stats,
            'avg_search_time_ms': avg_search_time * 1000,
            'avg_index_time_ms': avg_index_time * 1000,
            'provider_type': type(self.provider).__name__,
            'embedding_dimension': self.provider.dimension
        }


async def simulate_chat_session(system: ChatMemorySystem):
    """æ¨¡æ‹ŸçœŸå®çš„ Chat ä¼šè¯"""
    
    print("\n" + "="*70)
    print("ğŸ¤– ArrowEngine Agent-Chat å®é™…ç¯å¢ƒæµ‹è¯•")
    print("="*70)
    
    # 1. æ¨¡æ‹Ÿå¯¹è¯å†å²
    print("\nğŸ“ Phase 1: æ·»åŠ å¯¹è¯å†å²...")
    
    conversation_history = [
        ("user", "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æœºå™¨å­¦ä¹ "),
        ("assistant", "ä½ å¥½ï¼æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹ã€‚"),
        ("user", "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ä¸»è¦ç±»å‹ï¼Ÿ"),
        ("assistant", "æœºå™¨å­¦ä¹ ä¸»è¦åˆ†ä¸ºä¸‰ç±»ï¼šç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°æ•°æ®ï¼Œæ— ç›‘ç£å­¦ä¹ å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼ï¼Œå¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™æ¥å­¦ä¹ ã€‚"),
        ("user", "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"),
        ("assistant", "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚è¡¨ç¤ºã€‚å®ƒåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚"),
        ("user", "Python åœ¨æœºå™¨å­¦ä¹ ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ"),
        ("assistant", "Python æ˜¯æœºå™¨å­¦ä¹ æœ€æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œå› ä¸ºå®ƒæœ‰ä¸°å¯Œçš„åº“ï¼ˆå¦‚ scikit-learnã€TensorFlowã€PyTorchï¼‰å’Œç®€æ´çš„è¯­æ³•ã€‚"),
        ("user", "èƒ½ç»™æˆ‘æ¨èä¸€äº›å­¦ä¹ èµ„æºå—ï¼Ÿ"),
        ("assistant", "å½“ç„¶ï¼æˆ‘æ¨èï¼š1) Andrew Ng çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œ2) fast.ai çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œ3) Kaggle çš„å®è·µé¡¹ç›®ã€‚"),
    ]
    
    start_time = time.time()
    
    for i, (role, content) in enumerate(conversation_history):
        message_id = f"msg_{i+1}"
        await system.add_chat_message(
            message_id=message_id,
            role=role,
            content=content,
            metadata={'turn': i+1}
        )
        print(f"  âœ“ [{role:10s}] {content[:60]}...")
    
    # ç­‰å¾…ç´¢å¼•å®Œæˆ
    await system.background_queue.wait_until_empty(timeout=30.0)
    
    elapsed = time.time() - start_time
    print(f"\n  â±ï¸  æ·»åŠ  {len(conversation_history)} æ¡æ¶ˆæ¯: {elapsed:.2f}s")
    print(f"  ğŸ“Š å¹³å‡é€Ÿåº¦: {len(conversation_history)/elapsed:.1f} messages/s")
    
    # 2. æµ‹è¯•è¯­ä¹‰æœç´¢
    print("\nğŸ” Phase 2: æµ‹è¯•è¯­ä¹‰æœç´¢...")
    
    test_queries = [
        "æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œ",
        "Python ç¼–ç¨‹è¯­è¨€",
        "å­¦ä¹ èµ„æºæ¨è",
        "æœºå™¨å­¦ä¹ çš„åˆ†ç±»"
    ]
    
    for query in test_queries:
        print(f"\n  Query: {query}")
        
        results = await system.search_relevant_context(
            query=query,
            top_k=3,
            mode=SearchMode.SEMANTIC
        )
        
        if results:
            print(f"  Found {len(results)} results:")
            for j, result in enumerate(results[:3], 1):
                print(f"    {j}. [{result.memory_id}] similarity={result.similarity:.3f}")
                if result.memory:
                    context = result.memory.get('context', '')
                    print(f"       {context[:80]}...")
        else:
            print("  âš ï¸  No results found")
    
    # 3. æµ‹è¯•æ··åˆæœç´¢
    print("\nğŸ”€ Phase 3: æµ‹è¯•æ··åˆæœç´¢...")
    
    results = await system.search_relevant_context(
        query="æœºå™¨å­¦ä¹  Python",
        top_k=5,
        mode=SearchMode.HYBRID
    )
    
    print(f"  Found {len(results)} results with HYBRID mode")
    for i, result in enumerate(results[:3], 1):
        print(f"    {i}. similarity={result.similarity:.3f}")
    
    # 4. æ€§èƒ½ç»Ÿè®¡
    print("\nğŸ“Š Phase 4: æ€§èƒ½ç»Ÿè®¡...")
    
    stats = system.get_stats()
    
    print(f"\n  Provider: {stats['provider_type']}")
    print(f"  Embedding Dimension: {stats['embedding_dimension']}")
    print(f"\n  Memories Added: {stats['memories_added']}")
    print(f"  Searches Performed: {stats['searches_performed']}")
    print(f"\n  Avg Index Time: {stats['avg_index_time_ms']:.2f}ms")
    print(f"  Avg Search Time: {stats['avg_search_time_ms']:.2f}ms")
    print(f"\n  Total Index Time: {stats['total_index_time']:.2f}s")
    print(f"  Total Search Time: {stats['total_search_time']:.2f}s")
    
    # 5. ç´¢å¼•ç»Ÿè®¡
    print("\nğŸ“ˆ Phase 5: ç´¢å¼•ç»Ÿè®¡...")
    
    index_size = system.index_db.get_category_size("chat")
    categories = system.index_db.get_categories()
    
    print(f"  Indexed Memories: {index_size}")
    print(f"  Categories: {categories}")
    
    # 6. å‹åŠ›æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    print("\nğŸ’ª Phase 6: å‹åŠ›æµ‹è¯•...")
    
    print("  Adding 50 more messages...")
    stress_start = time.time()
    
    for i in range(50):
        await system.add_chat_message(
            message_id=f"stress_msg_{i}",
            role="user" if i % 2 == 0 else "assistant",
            content=f"Stress test message {i}: This is a test message for performance evaluation.",
            metadata={'stress_test': True}
        )
    
    await system.background_queue.wait_until_empty(timeout=60.0)
    stress_elapsed = time.time() - stress_start
    
    print(f"  âœ“ Added 50 messages in {stress_elapsed:.2f}s")
    print(f"  âœ“ Throughput: {50/stress_elapsed:.1f} messages/s")
    
    # 7. æœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š Phase 7: æœ€ç»ˆç»Ÿè®¡...")
    
    final_stats = system.get_stats()
    final_index_size = system.index_db.get_category_size("chat")
    
    print(f"\n  Total Memories: {final_stats['memories_added']}")
    print(f"  Total Searches: {final_stats['searches_performed']}")
    print(f"  Index Size: {final_index_size}")
    print(f"\n  Overall Avg Index Time: {final_stats['avg_index_time_ms']:.2f}ms")
    print(f"  Overall Avg Search Time: {final_stats['avg_search_time_ms']:.2f}ms")
    
    # å®Œæˆ
    print("\n" + "="*70)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*70)
    
    # è¯„ä¼°ç»“æœ
    print("\nğŸ“‹ è¯„ä¼°ç»“æœ:")
    
    if stats['provider_type'] == 'ArrowEngineProvider':
        print("  âœ… ä½¿ç”¨ ArrowEngine (é«˜æ€§èƒ½æ¨¡å¼)")
    else:
        print("  âš ï¸  ä½¿ç”¨ SentenceTransformerProvider (å›é€€æ¨¡å¼)")
    
    if final_stats['avg_search_time_ms'] < 100:
        print(f"  âœ… æœç´¢æ€§èƒ½ä¼˜ç§€ ({final_stats['avg_search_time_ms']:.2f}ms < 100ms)")
    elif final_stats['avg_search_time_ms'] < 500:
        print(f"  âœ“  æœç´¢æ€§èƒ½è‰¯å¥½ ({final_stats['avg_search_time_ms']:.2f}ms < 500ms)")
    else:
        print(f"  âš ï¸  æœç´¢æ€§èƒ½éœ€è¦ä¼˜åŒ– ({final_stats['avg_search_time_ms']:.2f}ms)")
    
    if final_stats['avg_index_time_ms'] < 50:
        print(f"  âœ… ç´¢å¼•æ€§èƒ½ä¼˜ç§€ ({final_stats['avg_index_time_ms']:.2f}ms < 50ms)")
    elif final_stats['avg_index_time_ms'] < 200:
        print(f"  âœ“  ç´¢å¼•æ€§èƒ½è‰¯å¥½ ({final_stats['avg_index_time_ms']:.2f}ms < 200ms)")
    else:
        print(f"  âš ï¸  ç´¢å¼•æ€§èƒ½éœ€è¦ä¼˜åŒ– ({final_stats['avg_index_time_ms']:.2f}ms)")
    
    if final_index_size == final_stats['memories_added']:
        print(f"  âœ… ç´¢å¼•å®Œæ•´æ€§éªŒè¯é€šè¿‡ ({final_index_size}/{final_stats['memories_added']})")
    else:
        print(f"  âš ï¸  ç´¢å¼•å®Œæ•´æ€§é—®é¢˜ ({final_index_size}/{final_stats['memories_added']})")
    
    print("\nğŸ’¡ å»ºè®®:")
    if stats['provider_type'] != 'ArrowEngineProvider':
        print("  - è¿è¡Œ 'python scripts/convert_and_validate.py' è½¬æ¢æ¨¡å‹ä»¥ä½¿ç”¨ ArrowEngine")
    print("  - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ GPU ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
    print("  - æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´ batch_size å‚æ•°")
    print("  - ç›‘æ§å†…å­˜ä½¿ç”¨å’Œç´¢å¼•å¤§å°")


async def main():
    """ä¸»å‡½æ•°"""
    system = None
    
    try:
        # åˆ›å»ºç³»ç»Ÿ
        system = ChatMemorySystem(data_dir="./test_chat_data")
        
        # å¯åŠ¨ç³»ç»Ÿ
        await system.start()
        
        # è¿è¡Œæµ‹è¯•
        await simulate_chat_session(system)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
        
    finally:
        # æ¸…ç†
        if system:
            await system.stop()
            print("\nğŸ§¹ ç³»ç»Ÿå·²æ¸…ç†")


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
