#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨ç‰ˆæœ¬ - å»¶è¿ŸåŠ è½½æ‰€æœ‰æ¨¡å‹
"""
import asyncio
import sys

from llm_compression import (
    LLMClient,
    LLMCompressor,
    ModelSelector,
    ConversationalAgent,
)


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆé¿å…HuggingFaceè¿æ¥è¶…æ—¶ï¼‰
    import os
    os.environ['HF_HUB_OFFLINE'] = '1'
    os.environ['TRANSFORMERS_OFFLINE'] = '1'
    
    print("ğŸš€ Quick Start (å»¶è¿ŸåŠ è½½æ¨¡å¼)...")
    
    # 1. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆä¸è¿æ¥ï¼‰
    print("  âœ“ LLM Client")
    llm_client = LLMClient(
        endpoint="http://localhost:11434",
        timeout=30.0
    )
    
    # 2. åˆå§‹åŒ–å‹ç¼©å™¨ï¼ˆä¸åŠ è½½embeddingï¼‰
    print("  âœ“ Compressor (embeddingå»¶è¿ŸåŠ è½½)")
    model_selector = ModelSelector()
    compressor = LLMCompressor(
        llm_client=llm_client,
        model_selector=model_selector,
        prewarm_embedding=False  # å…³é”®ï¼šä¸é¢„çƒ­
    )
    
    # 3. åˆå§‹åŒ–è®¤çŸ¥å¾ªç¯ï¼ˆæœ€å°é…ç½®ï¼‰
    print("  âœ“ Cognitive Loop")
    from llm_compression.expression_layer import MultiModalExpressor
    from llm_compression.internal_feedback import InternalFeedbackSystem
    from llm_compression.connection_learner import ConnectionLearner
    from llm_compression.network_navigator import NetworkNavigator
    from llm_compression.reconstructor import LLMReconstructor
    from llm_compression.cognitive_loop import CognitiveLoop
    
    reconstructor = LLMReconstructor(llm_client=llm_client)
    expressor = MultiModalExpressor(llm_client=llm_client, reconstructor=reconstructor)
    feedback = InternalFeedbackSystem()
    learner = ConnectionLearner()
    navigator = NetworkNavigator()
    
    cognitive_loop = CognitiveLoop(
        expressor=expressor,
        feedback=feedback,
        learner=learner,
        navigator=navigator,
        quality_threshold=0.0,
        max_corrections=0
    )
    
    # 4. åˆ›å»ºAgent
    print("  âœ“ Agent")
    agent = ConversationalAgent(
        llm_client=llm_client,
        compressor=compressor,
        cognitive_loop=cognitive_loop,
        enable_personalization=False  # æš‚æ—¶ç¦ç”¨ä¸ªæ€§åŒ–
    )
    
    print("\nâœ… åˆå§‹åŒ–å®Œæˆï¼å¼€å§‹å¯¹è¯...\n")
    print("=" * 60)
    
    # ç®€å•å¯¹è¯å¾ªç¯
    while True:
        try:
            user_input = input("\nğŸ’¬ You: ").strip()
            
            if not user_input:
                continue
            
            if user_input in ["/quit", "/exit"]:
                print("ğŸ‘‹ Goodbye!")
                break
            
            print("ğŸ¤” Agent is thinking...")
            
            # é¦–æ¬¡è°ƒç”¨æ—¶ä¼šåŠ è½½embeddingï¼ˆè¿™é‡Œæ‰ä¼šå¡ï¼‰
            response = await agent.chat(user_input)
            
            print(f"\nğŸ¤– Agent: {response.message}")
            print(f"   ğŸ“Š Quality: {response.quality_score:.2f} | "
                  f"Memories: {len(response.memories_used)}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
