"""
Cognitive Loop Demo - Simplified Version (Mock LLM)

å¿«é€Ÿæ¼”ç¤ºè®¤çŸ¥é—­ç¯ç³»ç»Ÿï¼Œä½¿ç”¨æ¨¡æ‹Ÿçš„LLMå“åº”
"""

import asyncio
import numpy as np
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock

from llm_compression import (
    MemoryPrimitive,
    CognitiveLoop,
    MultiModalExpressor,
    InternalFeedbackSystem,
    ExpressionResult,
    QualityScore,
    CompressedMemory,
    CompressionMetadata
)


def create_mock_memory(id: str, text: str) -> MemoryPrimitive:
    """åˆ›å»ºæ¨¡æ‹Ÿè®°å¿†"""
    metadata = CompressionMetadata(
        original_size=len(text),
        compressed_size=len(text),
        compression_ratio=1.0,
        model_used="mock",
        quality_score=0.9,
        compression_time_ms=10.0,
        compressed_at=datetime.now()
    )
    
    compressed = CompressedMemory(
        memory_id=id,
        summary_hash=f"hash_{id}",
        entities={},
        diff_data=text.encode(),
        embedding=[0.1] * 384,
        compression_metadata=metadata
    )
    
    embedding = np.random.randn(384)
    embedding = embedding / np.linalg.norm(embedding)
    
    return MemoryPrimitive(
        id=id,
        content=compressed,
        embedding=embedding
    )


async def main():
    """ä¸»æ¼”ç¤ºæµç¨‹"""
    print("\n" + "="*60)
    print("ğŸš€ Phase 2.0 è®¤çŸ¥é—­ç¯ç³»ç»Ÿæ¼”ç¤º (ç®€åŒ–ç‰ˆ)")
    print("="*60)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ­¥éª¤1: åˆ›å»ºè®°å¿†ç½‘ç»œ
    print("\n" + "="*60)
    print("ğŸ“¦ æ­¥éª¤1: æ„å»ºè®°å¿†ç½‘ç»œ")
    print("="*60)
    
    memories = [
        create_mock_memory("mem_0", "Python is a high-level programming language."),
        create_mock_memory("mem_1", "Python is used for web development and AI."),
        create_mock_memory("mem_2", "Machine learning is a subset of AI."),
        create_mock_memory("mem_3", "Deep learning uses neural networks."),
        create_mock_memory("mem_4", "NLP helps computers understand language."),
    ]
    
    print(f"\nâœ… åˆ›å»ºäº† {len(memories)} ä¸ªè®°å¿†å•å…ƒ")
    for mem in memories:
        print(f"   - {mem.id}: {mem.content.diff_data.decode()[:50]}...")
    
    # æ­¥éª¤2: åˆ›å»ºè®¤çŸ¥å¾ªç¯ï¼ˆä½¿ç”¨mockï¼‰
    print("\n" + "="*60)
    print("ğŸ§  æ­¥éª¤2: åˆå§‹åŒ–è®¤çŸ¥å¾ªç¯")
    print("="*60)
    
    # Mock expressor
    expressor = MagicMock()
    expressor.express_text = AsyncMock(return_value=ExpressionResult(
        content="Python is a versatile programming language used in web development, data science, and AI.",
        quality_score=0.92,
        modality="text",
        source_memories=["mem_0", "mem_1"]
    ))
    
    # Mock feedback
    feedback = MagicMock()
    feedback.evaluate = AsyncMock(return_value=QualityScore(
        overall=0.92,
        consistency=0.90,
        completeness=0.93,
        accuracy=0.91,
        coherence=0.94
    ))
    
    # åˆ›å»ºè®¤çŸ¥å¾ªç¯
    loop = CognitiveLoop(
        expressor=expressor,
        feedback=feedback,
        quality_threshold=0.85,
        max_corrections=2,
        learning_rate=0.1
    )
    
    # æ·»åŠ è®°å¿†
    for memory in memories:
        loop.add_memory(memory)
    
    print(f"\nâœ… è®¤çŸ¥å¾ªç¯å·²åˆå§‹åŒ–")
    print(f"   - è®°å¿†æ•°é‡: {len(memories)}")
    print(f"   - è´¨é‡é˜ˆå€¼: {loop.quality_threshold}")
    print(f"   - æœ€å¤§çº æ­£æ¬¡æ•°: {loop.max_corrections}")
    print(f"   - å­¦ä¹ ç‡: {loop.learning_rate}")
    
    # è®°å½•åˆå§‹ç»Ÿè®¡
    initial_stats = loop.get_network_stats()
    print(f"\nğŸ“Š åˆå§‹ç½‘ç»œçŠ¶æ€:")
    print(f"   - æ€»è®°å¿†æ•°: {initial_stats['total_memories']}")
    print(f"   - æ€»è¿æ¥æ•°: {initial_stats['total_connections']}")
    print(f"   - å¹³å‡è¿æ¥: {initial_stats['avg_connections']:.2f}")
    
    # æ­¥éª¤3: å¤„ç†æŸ¥è¯¢
    print("\n" + "="*60)
    print("ğŸ’¬ æ­¥éª¤3: å¤„ç†æŸ¥è¯¢")
    print("="*60)
    
    queries = [
        "What is Python used for?",
        "Explain machine learning",
        "How does deep learning work?"
    ]
    
    for i, query in enumerate(queries):
        print(f"\n{'â”€'*60}")
        print(f"æŸ¥è¯¢ {i+1}: {query}")
        print(f"{'â”€'*60}")
        
        # åˆ›å»ºæŸ¥è¯¢embedding
        query_embedding = np.random.randn(384)
        query_embedding = query_embedding / np.linalg.norm(query_embedding)
        
        # å¤„ç†æŸ¥è¯¢
        print("\nğŸ”„ æ‰§è¡Œè®¤çŸ¥å¾ªç¯...")
        result = await loop.process(
            query=query,
            query_embedding=query_embedding,
            max_memories=3
        )
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š ç»“æœ:")
        print(f"   - è¾“å‡º: {result.output[:80]}...")
        print(f"   - è´¨é‡è¯„åˆ†: {result.quality.overall:.2f}")
        print(f"   - ä½¿ç”¨è®°å¿†: {len(result.memories_used)} ä¸ª")
        print(f"   - çº æ­£æ¬¡æ•°: {result.corrections_applied}")
        print(f"   - å‘ç”Ÿå­¦ä¹ : {'æ˜¯' if result.learning_occurred else 'å¦'}")
        
        print(f"\nğŸ“ˆ è´¨é‡è¯¦æƒ…:")
        print(f"   - ä¸€è‡´æ€§: {result.quality.consistency:.2f}")
        print(f"   - å®Œæ•´æ€§: {result.quality.completeness:.2f}")
        print(f"   - å‡†ç¡®æ€§: {result.quality.accuracy:.2f}")
        print(f"   - è¿è´¯æ€§: {result.quality.coherence:.2f}")
    
    # æ­¥éª¤4: å±•ç¤ºç½‘ç»œæ¼”åŒ–
    print("\n" + "="*60)
    print("ğŸ“ˆ æ­¥éª¤4: ç½‘ç»œæ¼”åŒ–ç»Ÿè®¡")
    print("="*60)
    
    final_stats = loop.get_network_stats()
    
    print(f"\nåˆå§‹çŠ¶æ€:")
    print(f"   - è®°å¿†æ•°é‡: {initial_stats['total_memories']}")
    print(f"   - æ€»è¿æ¥æ•°: {initial_stats['total_connections']}")
    print(f"   - å¹³å‡è¿æ¥: {initial_stats['avg_connections']:.2f}")
    print(f"   - å¹³å‡æˆåŠŸç‡: {initial_stats['avg_success_rate']:.2f}")
    
    print(f"\næœ€ç»ˆçŠ¶æ€:")
    print(f"   - è®°å¿†æ•°é‡: {final_stats['total_memories']}")
    print(f"   - æ€»è¿æ¥æ•°: {final_stats['total_connections']}")
    print(f"   - å¹³å‡è¿æ¥: {final_stats['avg_connections']:.2f}")
    print(f"   - å¹³å‡æˆåŠŸç‡: {final_stats['avg_success_rate']:.2f}")
    
    print(f"\nå˜åŒ–:")
    print(f"   - è¿æ¥å¢é•¿: +{final_stats['total_connections'] - initial_stats['total_connections']}")
    print(f"   - å¹³å‡è¿æ¥å¢é•¿: +{final_stats['avg_connections'] - initial_stats['avg_connections']:.2f}")
    print(f"   - æˆåŠŸç‡å˜åŒ–: +{final_stats['avg_success_rate'] - initial_stats['avg_success_rate']:.2f}")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("="*60)
    print("\nå…³é”®æˆå°±:")
    print("  âœ… è®°å¿†ç½‘ç»œæ„å»º")
    print("  âœ… å®Œæ•´è®¤çŸ¥å¾ªç¯")
    print("  âœ… è´¨é‡è¯„ä¼° (>0.85)")
    print("  âœ… Hebbianå­¦ä¹ ")
    print("  âœ… ç½‘ç»œè‡ªç»„ç»‡")
    print(f"\nç½‘ç»œæ¼”åŒ–:")
    print(f"  - æ–°å¢è¿æ¥: {final_stats['total_connections'] - initial_stats['total_connections']}")
    print(f"  - æˆåŠŸç‡: {final_stats['avg_success_rate']:.1%}")
    print("\nè¿™æ˜¯ä¸€ä¸ªçœŸæ­£çš„è‡ªç»„ç»‡è®¤çŸ¥ç³»ç»Ÿï¼ğŸ§ âœ¨")


if __name__ == "__main__":
    asyncio.run(main())
